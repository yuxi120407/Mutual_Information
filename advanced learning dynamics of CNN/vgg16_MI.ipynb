{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, optimizers, models\n",
    "import numpy as np\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:b1:00.0, compute capability: 7.0\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" \n",
    "config = tf.compat.v1.ConfigProto() \n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9 # GPU memory \n",
    "session = tf.compat.v1.Session(config=config)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.num_classes = 10\n",
    "        self.layer1 = tf.keras.Sequential([layers.Conv2D(64, (3, 3), activation='relu',padding='same'),\n",
    "                 layers.BatchNormalization(),\n",
    "                 layers.Dropout(0.3)\n",
    "            ])\n",
    "        \n",
    "        self.layer2 = tf.keras.Sequential([layers.Conv2D(64, (3, 3), activation='relu',padding='same'),\n",
    "                 layers.BatchNormalization(),\n",
    "                 layers.Dropout(0.3),\n",
    "                 layers.MaxPooling2D(pool_size=(2, 2))\n",
    "            ])\n",
    "        \n",
    "        self.layer3 = tf.keras.Sequential([layers.Conv2D(128, (3, 3), activation='relu',padding='same'),\n",
    "                 layers.BatchNormalization(),\n",
    "                 layers.Dropout(0.4)\n",
    "            ])\n",
    "        \n",
    "        self.layer4 = tf.keras.Sequential([layers.Conv2D(128, (3, 3), activation='relu',padding='same'),\n",
    "                 layers.BatchNormalization(),\n",
    "                 layers.MaxPooling2D(pool_size=(2, 2))\n",
    "                 \n",
    "            ])\n",
    "        \n",
    "        self.layer5 = tf.keras.Sequential([layers.Conv2D(256, (3, 3), activation='relu',padding='same'),\n",
    "                 layers.BatchNormalization(),\n",
    "                 layers.Dropout(0.4)\n",
    "            ])\n",
    "        \n",
    "        self.layer6 = tf.keras.Sequential([layers.Conv2D(256, (3, 3), activation='relu',padding='same'),\n",
    "                 layers.BatchNormalization(),\n",
    "                 layers.Dropout(0.4)\n",
    "            ])\n",
    "        self.layer7 = tf.keras.Sequential([layers.Conv2D(256, (3, 3), activation='relu',padding='same'),\n",
    "                 layers.BatchNormalization(),\n",
    "                 layers.MaxPooling2D(pool_size=(2, 2))\n",
    "                 \n",
    "            ])\n",
    "        \n",
    "        self.layer8 = tf.keras.Sequential([layers.Conv2D(512, (3, 3), activation='relu',padding='same'),\n",
    "                 layers.BatchNormalization(),\n",
    "                 layers.Dropout(0.4)\n",
    "            ])\n",
    "        \n",
    "        self.layer9 = tf.keras.Sequential([layers.Conv2D(512, (3, 3), activation='relu',padding='same'),\n",
    "                 layers.BatchNormalization(),\n",
    "                 layers.Dropout(0.4)\n",
    "            ])\n",
    "        \n",
    "        self.layer10 = tf.keras.Sequential([layers.Conv2D(512, (3, 3), activation='relu',padding='same'),\n",
    "                 layers.BatchNormalization(),\n",
    "                 layers.MaxPooling2D(pool_size=(2, 2))\n",
    "                 \n",
    "            ])\n",
    "        \n",
    "        self.layer11 = tf.keras.Sequential([layers.Conv2D(512, (3, 3), activation='relu',padding='same'),\n",
    "                 layers.BatchNormalization(),\n",
    "                 layers.Dropout(0.4)\n",
    "            ])\n",
    "        \n",
    "        self.layer12 = tf.keras.Sequential([layers.Conv2D(512, (3, 3), activation='relu',padding='same'),\n",
    "                 layers.BatchNormalization(),\n",
    "                 layers.Dropout(0.4)\n",
    "            ])\n",
    "        self.layer13 = tf.keras.Sequential([layers.Conv2D(512, (3, 3), activation='relu',padding='same'),\n",
    "                 layers.BatchNormalization(),\n",
    "                 layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "                 layers.Dropout(0.5)\n",
    "            ])\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.layer14 = tf.keras.Sequential([layers.Dense(512,activation='relu'),\n",
    "                                            layers.BatchNormalization(),\n",
    "                                            layers.Dropout(0.5)\n",
    "                                           ])\n",
    "        self.layer15 = tf.keras.Sequential([layers.Dense(64,activation='relu'),\n",
    "                                            layers.BatchNormalization(),\n",
    "                                            layers.Dropout(0.5)\n",
    "                                           ])\n",
    "        self.layer16 = layers.Dense(self.num_classes,activation='softmax')\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "        layer1 = self.layer1(x)\n",
    "        layer2 = self.layer2(layer1)\n",
    "        layer3 = self.layer3(layer2)\n",
    "        layer4 = self.layer4(layer3)\n",
    "        layer5 = self.layer5(layer4)\n",
    "        layer6 = self.layer6(layer5)\n",
    "        layer7 = self.layer7(layer6)\n",
    "        layer8 = self.layer8(layer7)\n",
    "        layer9 = self.layer9(layer8)\n",
    "        layer10 = self.layer10(layer9)\n",
    "        layer11 = self.layer11(layer10)\n",
    "        layer12 = self.layer12(layer11)\n",
    "        layer13 = self.layer13(layer12)\n",
    "        flatten = self.flatten(layer13)\n",
    "        layer14 = self.layer14(flatten)\n",
    "        layer15 = self.layer15(layer14)\n",
    "        layer16 = self.layer16(layer15)\n",
    "                                           \n",
    "\n",
    "        return [layer16,layer15,layer14,layer13,layer12,layer11,layer10,layer9,layer8,\n",
    "                layer7,layer6,layer5,layer4,layer3,layer2,layer1]\n",
    "    \n",
    "    def calculate_gram_mat(self,x):\n",
    "        x = tf.reshape(x,[x.shape[0],-1]) \n",
    "        dist = tf.norm(x[:,None]-x,axis=2)\n",
    "        dist = dist/tf.math.reduce_max(dist)\n",
    "        sigma = tf.reduce_mean(tf.sort(dist)[0][0:50])\n",
    "        k = tf.exp(-dist**2/sigma**2)\n",
    "        k = k/tf.linalg.trace(k)\n",
    "        return k\n",
    "    \n",
    "    def reyi_entropy(self,x):\n",
    "        alpha = 1.01\n",
    "        k = self.calculate_gram_mat(x)\n",
    "        eigv = tf.abs(tf.linalg.eigvalsh(k))\n",
    "        eig_pow = eigv**alpha\n",
    "        entropy = (1/(1-alpha))*np.math.log2(tf.reduce_sum(eig_pow))\n",
    "        return entropy\n",
    "    \n",
    "    def joint_entropy(self,x,y):\n",
    "        alpha = 1.01\n",
    "        x = self.calculate_gram_mat(x)\n",
    "        y = self.calculate_gram_mat(y)\n",
    "        k = (x*y)/tf.linalg.trace((x*y))\n",
    "        eigv = tf.abs(tf.linalg.eigvalsh(k))\n",
    "        eig_pow = eigv**alpha\n",
    "        entropy = (1/(1-alpha))*np.math.log2(tf.reduce_sum(eig_pow))\n",
    "        return entropy\n",
    "    \n",
    "    def calculate_MI(self,x,y):\n",
    "        return self.reyi_entropy(x)+self.reyi_entropy(y)-self.joint_entropy(x,y)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist,squareform\n",
    "x =tf.reshape(output_layer[13],[output_layer[13].shape[0],-1])\n",
    "#dist = tf.norm(x[:,None]-x,axis=2)\n",
    "#dist = dist/tf.math.reduce_max(dist)\n",
    "#sigma = tf.reduce_mean(tf.sort(dist)[0][0:10])\n",
    "#k = tf.exp(-dist**2/sigma**2)\n",
    "#k = k/tf.linalg.trace(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch = x_train[0:128,]\n",
    "y_batch = y_train[0:128,]\n",
    "x_batch = tf.convert_to_tensor(value =x_batch,dtype=tf.float32)\n",
    "y_batch = tf.convert_to_tensor(value =y_batch,dtype=tf.float32)\n",
    "output_layer = model(x_batch)\n",
    "output_layer.append(x_batch)\n",
    "output_layer.append(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=350569, shape=(128, 10), dtype=float32, numpy=\n",
       "array([[0.09993532, 0.09983256, 0.10004701, ..., 0.10005648, 0.09991161,\n",
       "        0.10012794],\n",
       "       [0.0999016 , 0.09978057, 0.10006706, ..., 0.10005266, 0.09991504,\n",
       "        0.1001463 ],\n",
       "       [0.09992305, 0.09979167, 0.10007317, ..., 0.1000281 , 0.09986632,\n",
       "        0.10015428],\n",
       "       ...,\n",
       "       [0.09990502, 0.09981117, 0.10006332, ..., 0.10007375, 0.0998693 ,\n",
       "        0.10015185],\n",
       "       [0.09994082, 0.09984569, 0.10005805, ..., 0.10005439, 0.09989827,\n",
       "        0.1001249 ],\n",
       "       [0.09993186, 0.09981057, 0.10005771, ..., 0.1000736 , 0.09989009,\n",
       "        0.10015498]], dtype=float32)>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_layer[0]\n",
    "#model.calculate_MI(output_layer[-2],output_layer[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = output_layer[10]\n",
    "x = tf.reshape(x,[x.shape[0],-1]) \n",
    "dist = tf.norm(x[:,None]-x,axis=2)\n",
    "dist = dist/tf.math.reduce_max(dist)\n",
    "sigma = tf.reduce_mean(tf.sort(dist)[0][0:50])\n",
    "#sigma = 1\n",
    "k = tf.exp(-dist**2/sigma**2)\n",
    "k = k/tf.linalg.trace(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=4221216, shape=(), dtype=float32, numpy=0.4070061>"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=349828, shape=(128, 8, 8, 256), dtype=float32, numpy=\n",
       "array([[[[0.00000000e+00, 5.99257601e-03, 3.00012268e-02, ...,\n",
       "          3.13162711e-03, 0.00000000e+00, 9.98819526e-03],\n",
       "         [0.00000000e+00, 0.00000000e+00, 3.45690399e-02, ...,\n",
       "          6.50547585e-03, 7.47220032e-03, 1.04582887e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 3.30239646e-02, ...,\n",
       "          0.00000000e+00, 3.45706881e-04, 0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00, 0.00000000e+00, 3.99915613e-02, ...,\n",
       "          0.00000000e+00, 5.79379092e-04, 2.23383717e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.39883151e-02, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 6.48447452e-03],\n",
       "         [0.00000000e+00, 0.00000000e+00, 6.59759576e-03, ...,\n",
       "          0.00000000e+00, 7.61434902e-04, 0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00, 2.52808165e-02, 3.49018760e-02, ...,\n",
       "          0.00000000e+00, 3.51314917e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 8.61974712e-03, 3.76212634e-02, ...,\n",
       "          0.00000000e+00, 6.57824874e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 3.11641991e-02, ...,\n",
       "          0.00000000e+00, 4.60224561e-02, 4.90652211e-03],\n",
       "         ...,\n",
       "         [0.00000000e+00, 0.00000000e+00, 2.18107477e-02, ...,\n",
       "          0.00000000e+00, 5.05964831e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 2.22227201e-02, ...,\n",
       "          0.00000000e+00, 2.86866054e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 5.39177563e-03, ...,\n",
       "          0.00000000e+00, 1.61223989e-02, 9.21632454e-04]],\n",
       "\n",
       "        [[0.00000000e+00, 1.22063309e-02, 4.69405092e-02, ...,\n",
       "          0.00000000e+00, 3.94574553e-02, 1.95775311e-02],\n",
       "         [0.00000000e+00, 1.94419769e-03, 3.19482163e-02, ...,\n",
       "          0.00000000e+00, 6.86244294e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 5.40391989e-02, ...,\n",
       "          0.00000000e+00, 6.93875179e-02, 2.37909406e-02],\n",
       "         ...,\n",
       "         [0.00000000e+00, 0.00000000e+00, 4.01814915e-02, ...,\n",
       "          0.00000000e+00, 5.82988113e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.50449481e-02, ...,\n",
       "          0.00000000e+00, 6.62502125e-02, 2.38717403e-04],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 6.92062732e-03, 0.00000000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.00000000e+00, 2.68579237e-02, 5.16628288e-02, ...,\n",
       "          0.00000000e+00, 6.38705492e-02, 9.27287620e-03],\n",
       "         [0.00000000e+00, 1.99895613e-02, 6.93736300e-02, ...,\n",
       "          0.00000000e+00, 1.02905534e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 4.30440949e-03, 4.35254648e-02, ...,\n",
       "          0.00000000e+00, 8.32654387e-02, 1.40320677e-02],\n",
       "         ...,\n",
       "         [0.00000000e+00, 1.55498618e-02, 3.80640067e-02, ...,\n",
       "          0.00000000e+00, 4.81140576e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 9.51810798e-04, 2.23780740e-02, ...,\n",
       "          0.00000000e+00, 4.41045724e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.88136678e-02, ...,\n",
       "          0.00000000e+00, 2.85135265e-02, 8.70735943e-03]],\n",
       "\n",
       "        [[0.00000000e+00, 1.62470329e-03, 7.39836022e-02, ...,\n",
       "          0.00000000e+00, 6.86809495e-02, 3.11693363e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 3.90321687e-02, ...,\n",
       "          0.00000000e+00, 7.54764751e-02, 9.65358876e-03],\n",
       "         [0.00000000e+00, 0.00000000e+00, 4.36198041e-02, ...,\n",
       "          0.00000000e+00, 6.05855249e-02, 6.99366443e-03],\n",
       "         ...,\n",
       "         [0.00000000e+00, 1.24671822e-02, 5.67340292e-02, ...,\n",
       "          0.00000000e+00, 1.60258748e-02, 2.29535531e-02],\n",
       "         [0.00000000e+00, 1.37295723e-02, 4.32399400e-02, ...,\n",
       "          0.00000000e+00, 3.40154432e-02, 2.06898991e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.66366329e-03, 8.31925217e-03]],\n",
       "\n",
       "        [[0.00000000e+00, 7.02589983e-03, 3.77198867e-02, ...,\n",
       "          0.00000000e+00, 4.31650653e-02, 1.56081412e-02],\n",
       "         [0.00000000e+00, 1.32205999e-02, 4.60182801e-02, ...,\n",
       "          0.00000000e+00, 3.60494256e-02, 2.55480781e-02],\n",
       "         [0.00000000e+00, 1.47426482e-02, 3.16056609e-02, ...,\n",
       "          0.00000000e+00, 3.67479026e-02, 1.84365697e-02],\n",
       "         ...,\n",
       "         [0.00000000e+00, 2.52060369e-02, 3.73914056e-02, ...,\n",
       "          0.00000000e+00, 3.83675545e-02, 1.91589091e-02],\n",
       "         [0.00000000e+00, 2.89268102e-02, 3.66949141e-02, ...,\n",
       "          0.00000000e+00, 2.84122638e-02, 3.47734950e-02],\n",
       "         [0.00000000e+00, 2.02647150e-02, 2.40138639e-03, ...,\n",
       "          0.00000000e+00, 2.19609477e-02, 1.89037733e-02]]],\n",
       "\n",
       "\n",
       "       [[[0.00000000e+00, 1.68716144e-02, 3.68993953e-02, ...,\n",
       "          1.40949842e-02, 7.17084017e-03, 6.06616400e-03],\n",
       "         [0.00000000e+00, 1.26686161e-02, 3.56679894e-02, ...,\n",
       "          1.13961175e-02, 0.00000000e+00, 2.51963474e-02],\n",
       "         [0.00000000e+00, 9.88197140e-03, 3.11232861e-02, ...,\n",
       "          2.08483320e-02, 0.00000000e+00, 2.52395254e-02],\n",
       "         ...,\n",
       "         [0.00000000e+00, 3.73284728e-03, 7.16612935e-02, ...,\n",
       "          1.96088608e-02, 0.00000000e+00, 3.23698036e-02],\n",
       "         [4.16946411e-03, 0.00000000e+00, 3.13907117e-02, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 4.78826882e-03],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.00110210e-02, ...,\n",
       "          0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00, 2.95855030e-02, 4.15292047e-02, ...,\n",
       "          0.00000000e+00, 6.37904257e-02, 3.93920578e-03],\n",
       "         [0.00000000e+00, 3.54145505e-02, 4.59572859e-02, ...,\n",
       "          0.00000000e+00, 8.81109610e-02, 1.34863546e-02],\n",
       "         [0.00000000e+00, 4.55078389e-03, 6.23855293e-02, ...,\n",
       "          0.00000000e+00, 1.15115598e-01, 0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00, 0.00000000e+00, 7.04186857e-02, ...,\n",
       "          0.00000000e+00, 6.55587390e-02, 2.79553514e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 3.25731225e-02, ...,\n",
       "          0.00000000e+00, 5.29493019e-02, 8.33569653e-03],\n",
       "         [0.00000000e+00, 0.00000000e+00, 6.80461479e-03, ...,\n",
       "          0.00000000e+00, 2.64064390e-02, 0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00, 2.43436731e-02, 3.09336595e-02, ...,\n",
       "          0.00000000e+00, 6.74991310e-02, 2.65835952e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 5.32003939e-02, ...,\n",
       "          0.00000000e+00, 1.26497298e-01, 2.23645233e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 8.01259726e-02, ...,\n",
       "          0.00000000e+00, 1.39077216e-01, 1.92099959e-02],\n",
       "         ...,\n",
       "         [0.00000000e+00, 0.00000000e+00, 7.76112899e-02, ...,\n",
       "          0.00000000e+00, 5.30905388e-02, 3.24395932e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 3.86193953e-02, ...,\n",
       "          0.00000000e+00, 4.60815988e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 5.78067172e-03, ...,\n",
       "          0.00000000e+00, 3.98241282e-02, 0.00000000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.00000000e+00, 4.37665321e-02, 6.31792545e-02, ...,\n",
       "          0.00000000e+00, 1.07903250e-01, 3.00822295e-02],\n",
       "         [0.00000000e+00, 6.10083938e-02, 5.21276295e-02, ...,\n",
       "          0.00000000e+00, 1.43179268e-01, 3.27392556e-02],\n",
       "         [0.00000000e+00, 9.73650068e-03, 9.51205194e-02, ...,\n",
       "          0.00000000e+00, 1.14245810e-01, 9.45380982e-03],\n",
       "         ...,\n",
       "         [0.00000000e+00, 0.00000000e+00, 4.02868055e-02, ...,\n",
       "          0.00000000e+00, 7.62560889e-02, 1.90587342e-02],\n",
       "         [0.00000000e+00, 1.00176618e-03, 2.95997187e-02, ...,\n",
       "          0.00000000e+00, 8.54357183e-02, 2.79948697e-03],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 2.93008313e-02, 8.36616661e-03]],\n",
       "\n",
       "        [[0.00000000e+00, 3.95850837e-02, 7.35056400e-02, ...,\n",
       "          0.00000000e+00, 7.74109066e-02, 2.31017843e-02],\n",
       "         [0.00000000e+00, 1.39019340e-02, 8.02987963e-02, ...,\n",
       "          0.00000000e+00, 1.08831689e-01, 4.48109694e-02],\n",
       "         [0.00000000e+00, 1.02321226e-02, 1.08523883e-01, ...,\n",
       "          0.00000000e+00, 9.56663564e-02, 6.94956109e-02],\n",
       "         ...,\n",
       "         [0.00000000e+00, 0.00000000e+00, 6.51754811e-02, ...,\n",
       "          0.00000000e+00, 9.71086696e-02, 2.75684111e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 3.59073430e-02, ...,\n",
       "          0.00000000e+00, 5.62990345e-02, 3.24795023e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.67104411e-02, 8.99792276e-03]],\n",
       "\n",
       "        [[0.00000000e+00, 3.77511010e-02, 2.39880309e-02, ...,\n",
       "          0.00000000e+00, 5.56494147e-02, 1.20425094e-02],\n",
       "         [0.00000000e+00, 2.19616536e-02, 3.88438702e-02, ...,\n",
       "          0.00000000e+00, 4.70448807e-02, 2.23243218e-02],\n",
       "         [0.00000000e+00, 2.85319723e-02, 3.98338251e-02, ...,\n",
       "          0.00000000e+00, 5.39777018e-02, 8.30480643e-03],\n",
       "         ...,\n",
       "         [0.00000000e+00, 1.83923673e-02, 5.03821895e-02, ...,\n",
       "          0.00000000e+00, 6.27442002e-02, 4.51368093e-02],\n",
       "         [0.00000000e+00, 3.65112275e-02, 4.19133157e-02, ...,\n",
       "          0.00000000e+00, 5.71929179e-02, 2.66485661e-02],\n",
       "         [0.00000000e+00, 8.58203229e-03, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 4.22311611e-02, 2.54436806e-02]]],\n",
       "\n",
       "\n",
       "       [[[0.00000000e+00, 4.36807424e-02, 3.90680917e-02, ...,\n",
       "          3.17993127e-02, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 5.18757999e-02, 6.94108903e-02, ...,\n",
       "          5.19349314e-02, 0.00000000e+00, 3.08289006e-02],\n",
       "         [0.00000000e+00, 3.21351513e-02, 5.48070110e-02, ...,\n",
       "          2.75073089e-02, 0.00000000e+00, 9.54016484e-03],\n",
       "         ...,\n",
       "         [0.00000000e+00, 7.35506229e-03, 5.42949289e-02, ...,\n",
       "          1.96505226e-02, 0.00000000e+00, 1.89162232e-02],\n",
       "         [0.00000000e+00, 2.70748604e-02, 4.40176949e-02, ...,\n",
       "          2.94274511e-03, 2.28627101e-02, 1.58373695e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 3.00737619e-02, ...,\n",
       "          9.36137047e-04, 2.17913743e-02, 2.25136243e-02]],\n",
       "\n",
       "        [[0.00000000e+00, 7.45574683e-02, 7.57815465e-02, ...,\n",
       "          0.00000000e+00, 1.02447920e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 7.38621876e-02, 7.05951750e-02, ...,\n",
       "          0.00000000e+00, 1.33388981e-01, 7.02561736e-02],\n",
       "         [0.00000000e+00, 3.01288068e-02, 9.24380794e-02, ...,\n",
       "          0.00000000e+00, 1.24202445e-01, 5.50897382e-02],\n",
       "         ...,\n",
       "         [0.00000000e+00, 5.13215773e-02, 4.63551991e-02, ...,\n",
       "          0.00000000e+00, 1.45886332e-01, 2.31592059e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.71152093e-02, ...,\n",
       "          0.00000000e+00, 1.05972253e-01, 3.36328857e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 2.03515925e-02, ...,\n",
       "          0.00000000e+00, 7.06802309e-02, 4.56595160e-02]],\n",
       "\n",
       "        [[0.00000000e+00, 3.55697982e-02, 6.77003339e-02, ...,\n",
       "          0.00000000e+00, 1.06354892e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 3.51051763e-02, 6.86337128e-02, ...,\n",
       "          6.86466973e-03, 1.46702483e-01, 4.35121395e-02],\n",
       "         [0.00000000e+00, 3.32314172e-03, 4.98004556e-02, ...,\n",
       "          0.00000000e+00, 8.95270482e-02, 3.16297971e-02],\n",
       "         ...,\n",
       "         [0.00000000e+00, 3.49226035e-02, 5.65579832e-02, ...,\n",
       "          0.00000000e+00, 1.70918792e-01, 3.42047848e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 3.15968096e-02, ...,\n",
       "          0.00000000e+00, 9.19972658e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 5.95145440e-03, 1.02336593e-02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.00000000e+00, 2.96609532e-02, 5.41051365e-02, ...,\n",
       "          0.00000000e+00, 6.33489862e-02, 6.12739194e-03],\n",
       "         [0.00000000e+00, 2.86779907e-02, 6.95123672e-02, ...,\n",
       "          0.00000000e+00, 8.99278522e-02, 9.68110096e-03],\n",
       "         [0.00000000e+00, 9.54989437e-03, 5.48427403e-02, ...,\n",
       "          0.00000000e+00, 9.29727480e-02, 0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00, 2.42040656e-03, 5.13005480e-02, ...,\n",
       "          0.00000000e+00, 9.22187716e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 3.03949192e-02, ...,\n",
       "          0.00000000e+00, 7.08285570e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 5.86488023e-02, 0.00000000e+00]],\n",
       "\n",
       "        [[0.00000000e+00, 2.08494402e-02, 5.01981825e-02, ...,\n",
       "          0.00000000e+00, 5.81494346e-02, 1.09641766e-02],\n",
       "         [0.00000000e+00, 1.22995581e-02, 6.28396049e-02, ...,\n",
       "          0.00000000e+00, 9.18447003e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 5.23036756e-02, ...,\n",
       "          0.00000000e+00, 8.64429474e-02, 0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00, 0.00000000e+00, 3.15311849e-02, ...,\n",
       "          0.00000000e+00, 7.88000301e-02, 1.04343826e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 2.40339078e-02, ...,\n",
       "          0.00000000e+00, 7.22197667e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.50174345e-02, 7.45899160e-04]],\n",
       "\n",
       "        [[0.00000000e+00, 1.37342960e-02, 2.06788257e-02, ...,\n",
       "          0.00000000e+00, 4.92660441e-02, 5.74486889e-03],\n",
       "         [0.00000000e+00, 7.32649304e-03, 2.53761448e-02, ...,\n",
       "          0.00000000e+00, 6.43084273e-02, 5.41861774e-03],\n",
       "         [0.00000000e+00, 8.97334795e-03, 2.60042306e-02, ...,\n",
       "          0.00000000e+00, 6.33883551e-02, 2.83445790e-03],\n",
       "         ...,\n",
       "         [0.00000000e+00, 1.92514751e-02, 1.11207534e-02, ...,\n",
       "          0.00000000e+00, 5.84655181e-02, 8.31367169e-03],\n",
       "         [0.00000000e+00, 6.37255190e-03, 8.05008691e-03, ...,\n",
       "          0.00000000e+00, 4.38990109e-02, 6.41014846e-03],\n",
       "         [0.00000000e+00, 1.24397891e-04, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 2.36130655e-02, 1.41174905e-02]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.00000000e+00, 3.60803455e-02, 4.59587201e-02, ...,\n",
       "          6.92436658e-03, 0.00000000e+00, 2.39878111e-02],\n",
       "         [0.00000000e+00, 1.06170299e-02, 3.80233340e-02, ...,\n",
       "          2.65939813e-02, 0.00000000e+00, 4.18743417e-02],\n",
       "         [0.00000000e+00, 5.27509721e-03, 4.78483252e-02, ...,\n",
       "          6.49730442e-03, 0.00000000e+00, 0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00, 2.94595752e-02, 6.70189932e-02, ...,\n",
       "          1.26017369e-02, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 3.12677994e-02, 4.25376073e-02, ...,\n",
       "          2.12141667e-02, 8.84411205e-03, 1.38406055e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 2.52638813e-02, ...,\n",
       "          1.35995634e-03, 2.74744071e-02, 3.29109654e-02]],\n",
       "\n",
       "        [[0.00000000e+00, 4.01945710e-02, 6.05960712e-02, ...,\n",
       "          0.00000000e+00, 6.81658611e-02, 4.25395230e-03],\n",
       "         [0.00000000e+00, 2.23601852e-02, 7.23569840e-02, ...,\n",
       "          0.00000000e+00, 1.10309072e-01, 3.68134268e-02],\n",
       "         [0.00000000e+00, 1.42244073e-02, 5.16310520e-02, ...,\n",
       "          0.00000000e+00, 1.17432423e-01, 1.10484539e-02],\n",
       "         ...,\n",
       "         [0.00000000e+00, 2.73307879e-02, 6.58863485e-02, ...,\n",
       "          0.00000000e+00, 1.16186425e-01, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 4.04171133e-03, ...,\n",
       "          0.00000000e+00, 1.20396227e-01, 1.30137969e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.33597413e-02, ...,\n",
       "          0.00000000e+00, 8.31107199e-02, 3.36358286e-02]],\n",
       "\n",
       "        [[2.65613035e-03, 2.99931131e-02, 6.21188879e-02, ...,\n",
       "          0.00000000e+00, 7.73379430e-02, 4.15733503e-03],\n",
       "         [0.00000000e+00, 0.00000000e+00, 8.00979361e-02, ...,\n",
       "          0.00000000e+00, 8.01146179e-02, 2.59838309e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 6.56697974e-02, ...,\n",
       "          0.00000000e+00, 9.74731743e-02, 3.71592343e-02],\n",
       "         ...,\n",
       "         [0.00000000e+00, 2.37108022e-02, 7.69356489e-02, ...,\n",
       "          0.00000000e+00, 1.38045460e-01, 1.69015564e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 5.55516593e-03, ...,\n",
       "          0.00000000e+00, 8.16250816e-02, 2.23575439e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 3.44698802e-02, 3.11076026e-02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.00000000e+00, 5.36224842e-02, 4.54474501e-02, ...,\n",
       "          0.00000000e+00, 6.46871552e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 2.46504657e-02, 7.81671256e-02, ...,\n",
       "          0.00000000e+00, 1.13011248e-01, 4.93779033e-02],\n",
       "         [0.00000000e+00, 6.01985375e-05, 5.23412786e-02, ...,\n",
       "          0.00000000e+00, 8.29664841e-02, 1.24569805e-02],\n",
       "         ...,\n",
       "         [0.00000000e+00, 0.00000000e+00, 3.93456817e-02, ...,\n",
       "          0.00000000e+00, 1.03215337e-01, 3.49675156e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.52154304e-02, ...,\n",
       "          0.00000000e+00, 6.30158037e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 6.28040656e-02, 2.39845123e-02]],\n",
       "\n",
       "        [[0.00000000e+00, 5.27268574e-02, 5.52887581e-02, ...,\n",
       "          0.00000000e+00, 6.04406334e-02, 6.30787574e-03],\n",
       "         [0.00000000e+00, 3.59383970e-02, 8.39499310e-02, ...,\n",
       "          0.00000000e+00, 8.61861855e-02, 6.08351603e-02],\n",
       "         [0.00000000e+00, 9.20880679e-03, 8.85047019e-02, ...,\n",
       "          0.00000000e+00, 8.23461935e-02, 6.76401258e-02],\n",
       "         ...,\n",
       "         [0.00000000e+00, 0.00000000e+00, 6.91146776e-02, ...,\n",
       "          0.00000000e+00, 7.31479973e-02, 6.84799626e-03],\n",
       "         [0.00000000e+00, 7.24337250e-03, 3.58194448e-02, ...,\n",
       "          0.00000000e+00, 4.68970425e-02, 2.42512655e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 4.40810360e-02, 3.36476415e-02]],\n",
       "\n",
       "        [[0.00000000e+00, 3.89919244e-02, 1.35660004e-02, ...,\n",
       "          0.00000000e+00, 7.44096786e-02, 9.64379963e-03],\n",
       "         [0.00000000e+00, 6.47923946e-02, 3.43809575e-02, ...,\n",
       "          0.00000000e+00, 7.29758143e-02, 6.17657648e-03],\n",
       "         [0.00000000e+00, 3.59861851e-02, 4.14167270e-02, ...,\n",
       "          0.00000000e+00, 5.06178774e-02, 2.63038985e-02],\n",
       "         ...,\n",
       "         [0.00000000e+00, 3.21667902e-02, 3.22898291e-02, ...,\n",
       "          0.00000000e+00, 6.70200288e-02, 1.63004398e-02],\n",
       "         [0.00000000e+00, 2.04774328e-02, 3.32659930e-02, ...,\n",
       "          0.00000000e+00, 3.36542502e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.96936950e-02, 5.26958262e-04, ...,\n",
       "          0.00000000e+00, 4.21533175e-02, 1.60428230e-02]]],\n",
       "\n",
       "\n",
       "       [[[0.00000000e+00, 2.53266003e-02, 2.08190307e-02, ...,\n",
       "          1.76624693e-02, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 2.37789266e-02, 2.35679261e-02, ...,\n",
       "          2.84288637e-02, 0.00000000e+00, 1.11859841e-02],\n",
       "         [0.00000000e+00, 2.69120988e-02, 2.05311254e-02, ...,\n",
       "          2.80900989e-02, 0.00000000e+00, 5.41885151e-03],\n",
       "         ...,\n",
       "         [0.00000000e+00, 1.65678505e-02, 4.34247665e-02, ...,\n",
       "          3.14020514e-02, 0.00000000e+00, 7.83108920e-03],\n",
       "         [0.00000000e+00, 2.46666558e-02, 2.58553084e-02, ...,\n",
       "          2.43979096e-02, 3.47092655e-03, 1.59382001e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.61395818e-02, ...,\n",
       "          5.30666439e-03, 1.36747099e-02, 2.52979770e-02]],\n",
       "\n",
       "        [[0.00000000e+00, 3.46191376e-02, 4.27618846e-02, ...,\n",
       "          0.00000000e+00, 5.37787378e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 3.18957306e-02, 5.30831330e-02, ...,\n",
       "          9.24002193e-03, 8.32332447e-02, 2.09503397e-02],\n",
       "         [0.00000000e+00, 1.95116121e-02, 6.24456927e-02, ...,\n",
       "          8.19877069e-03, 8.40030909e-02, 3.61756049e-02],\n",
       "         ...,\n",
       "         [0.00000000e+00, 1.82294603e-02, 8.50280747e-02, ...,\n",
       "          1.04228491e-02, 1.18241742e-01, 4.24533151e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 4.30359356e-02, ...,\n",
       "          0.00000000e+00, 1.12577870e-01, 5.34537956e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.75379124e-02, ...,\n",
       "          0.00000000e+00, 5.71089685e-02, 4.05611508e-02]],\n",
       "\n",
       "        [[0.00000000e+00, 3.00507378e-02, 4.79315743e-02, ...,\n",
       "          0.00000000e+00, 6.07334450e-02, 1.30694825e-02],\n",
       "         [0.00000000e+00, 2.86770929e-02, 4.03588042e-02, ...,\n",
       "          2.61330903e-02, 8.54639038e-02, 3.67211364e-02],\n",
       "         [0.00000000e+00, 1.36401653e-02, 5.54308295e-02, ...,\n",
       "          0.00000000e+00, 6.63586631e-02, 3.67682725e-02],\n",
       "         ...,\n",
       "         [0.00000000e+00, 9.07122623e-03, 6.43629730e-02, ...,\n",
       "          0.00000000e+00, 7.81580284e-02, 3.80046852e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 2.23903302e-02, ...,\n",
       "          0.00000000e+00, 7.43431672e-02, 4.51215170e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 2.61952169e-03, ...,\n",
       "          0.00000000e+00, 3.29663455e-02, 4.42140065e-02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.00000000e+00, 3.17118615e-02, 4.57101725e-02, ...,\n",
       "          0.00000000e+00, 4.98139001e-02, 4.30210726e-03],\n",
       "         [0.00000000e+00, 2.01744381e-02, 6.11957796e-02, ...,\n",
       "          0.00000000e+00, 9.43608284e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 6.43857345e-02, ...,\n",
       "          0.00000000e+00, 7.31318220e-02, 0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00, 1.19311735e-02, 4.82652336e-02, ...,\n",
       "          0.00000000e+00, 9.80563089e-02, 1.24522345e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 4.00889553e-02, ...,\n",
       "          0.00000000e+00, 9.08758715e-02, 2.71974783e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 7.15917442e-03, ...,\n",
       "          0.00000000e+00, 3.33825797e-02, 1.80756059e-02]],\n",
       "\n",
       "        [[0.00000000e+00, 3.47774960e-02, 3.40260863e-02, ...,\n",
       "          0.00000000e+00, 4.82771732e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 1.94532629e-02, 2.48420183e-02, ...,\n",
       "          0.00000000e+00, 6.98037744e-02, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 4.74238843e-02, ...,\n",
       "          0.00000000e+00, 6.58442080e-02, 0.00000000e+00],\n",
       "         ...,\n",
       "         [0.00000000e+00, 1.51947548e-04, 3.20055857e-02, ...,\n",
       "          0.00000000e+00, 9.07877237e-02, 2.01011207e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 2.52511986e-02, ...,\n",
       "          0.00000000e+00, 8.27781707e-02, 2.05170084e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 1.25738224e-02, 1.64532438e-02]],\n",
       "\n",
       "        [[0.00000000e+00, 1.51066920e-02, 2.33164541e-02, ...,\n",
       "          0.00000000e+00, 4.96934503e-02, 3.85103445e-03],\n",
       "         [0.00000000e+00, 1.42158475e-02, 2.71074381e-02, ...,\n",
       "          0.00000000e+00, 8.17721486e-02, 9.17559210e-03],\n",
       "         [0.00000000e+00, 0.00000000e+00, 2.59357113e-02, ...,\n",
       "          0.00000000e+00, 8.30967203e-02, 5.30771073e-03],\n",
       "         ...,\n",
       "         [0.00000000e+00, 1.52026564e-02, 3.72517668e-02, ...,\n",
       "          0.00000000e+00, 8.27761889e-02, 1.44732445e-02],\n",
       "         [0.00000000e+00, 3.32469121e-02, 2.64059957e-02, ...,\n",
       "          0.00000000e+00, 5.82375862e-02, 2.85159387e-02],\n",
       "         [0.00000000e+00, 1.91363394e-02, 6.39081874e-04, ...,\n",
       "          0.00000000e+00, 2.88352240e-02, 1.54931825e-02]]],\n",
       "\n",
       "\n",
       "       [[[0.00000000e+00, 2.67730989e-02, 3.45501564e-02, ...,\n",
       "          1.24062793e-02, 0.00000000e+00, 1.47633618e-02],\n",
       "         [0.00000000e+00, 3.32387760e-02, 3.51641513e-02, ...,\n",
       "          4.57538664e-02, 0.00000000e+00, 3.91321182e-02],\n",
       "         [0.00000000e+00, 3.44054922e-02, 7.36070722e-02, ...,\n",
       "          1.53203439e-02, 0.00000000e+00, 1.70829706e-02],\n",
       "         ...,\n",
       "         [0.00000000e+00, 4.27311175e-02, 7.57501423e-02, ...,\n",
       "          2.69642193e-02, 0.00000000e+00, 1.15430281e-02],\n",
       "         [0.00000000e+00, 4.10154723e-02, 4.03874442e-02, ...,\n",
       "          1.85413808e-02, 0.00000000e+00, 1.15023442e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 2.29928363e-02, ...,\n",
       "          0.00000000e+00, 2.01637093e-02, 2.57774852e-02]],\n",
       "\n",
       "        [[0.00000000e+00, 3.22810113e-02, 7.51643851e-02, ...,\n",
       "          0.00000000e+00, 9.26559269e-02, 1.79767888e-03],\n",
       "         [0.00000000e+00, 4.92603742e-02, 7.19298422e-02, ...,\n",
       "          0.00000000e+00, 1.01722904e-01, 1.72823779e-02],\n",
       "         [0.00000000e+00, 2.59312205e-02, 9.89717171e-02, ...,\n",
       "          0.00000000e+00, 1.08199090e-01, 4.89104763e-02],\n",
       "         ...,\n",
       "         [0.00000000e+00, 2.37562675e-02, 1.00027621e-01, ...,\n",
       "          0.00000000e+00, 1.15997136e-01, 3.16080078e-02],\n",
       "         [0.00000000e+00, 9.95719340e-04, 3.92527804e-02, ...,\n",
       "          0.00000000e+00, 1.19301744e-01, 3.49685885e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 2.49372479e-02, ...,\n",
       "          0.00000000e+00, 7.11890236e-02, 5.11710271e-02]],\n",
       "\n",
       "        [[0.00000000e+00, 2.37118155e-02, 4.50503528e-02, ...,\n",
       "          0.00000000e+00, 1.05510361e-01, 6.32775901e-03],\n",
       "         [0.00000000e+00, 6.44918308e-02, 8.96636993e-02, ...,\n",
       "          0.00000000e+00, 1.36532336e-01, 3.75163667e-02],\n",
       "         [0.00000000e+00, 2.38363314e-02, 8.66266116e-02, ...,\n",
       "          0.00000000e+00, 1.13904238e-01, 3.05556562e-02],\n",
       "         ...,\n",
       "         [0.00000000e+00, 1.53954392e-02, 7.70486966e-02, ...,\n",
       "          0.00000000e+00, 1.02864757e-01, 5.20084389e-02],\n",
       "         [0.00000000e+00, 4.77819936e-03, 1.97772272e-02, ...,\n",
       "          0.00000000e+00, 6.95160031e-02, 1.96905155e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.43118179e-03, ...,\n",
       "          0.00000000e+00, 3.15573066e-02, 3.26006599e-02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.00000000e+00, 1.69985108e-02, 5.33759966e-02, ...,\n",
       "          0.00000000e+00, 7.55696967e-02, 1.03039080e-02],\n",
       "         [0.00000000e+00, 7.30663352e-03, 8.85394514e-02, ...,\n",
       "          0.00000000e+00, 1.03661515e-01, 3.20558660e-02],\n",
       "         [0.00000000e+00, 1.45277716e-02, 6.78210482e-02, ...,\n",
       "          0.00000000e+00, 7.57856295e-02, 1.32388119e-02],\n",
       "         ...,\n",
       "         [0.00000000e+00, 0.00000000e+00, 4.09604013e-02, ...,\n",
       "          0.00000000e+00, 5.50939403e-02, 2.10524853e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 5.03508858e-02, ...,\n",
       "          0.00000000e+00, 6.77390248e-02, 2.38648374e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 1.97965428e-02, ...,\n",
       "          0.00000000e+00, 1.24325743e-02, 7.99281150e-03]],\n",
       "\n",
       "        [[0.00000000e+00, 3.54569592e-02, 4.09745239e-02, ...,\n",
       "          0.00000000e+00, 4.94305640e-02, 8.46224092e-03],\n",
       "         [0.00000000e+00, 9.00540315e-03, 7.28774816e-02, ...,\n",
       "          0.00000000e+00, 4.57222275e-02, 3.06922533e-02],\n",
       "         [0.00000000e+00, 2.64661014e-02, 4.93693762e-02, ...,\n",
       "          0.00000000e+00, 2.99133658e-02, 2.48744451e-02],\n",
       "         ...,\n",
       "         [0.00000000e+00, 0.00000000e+00, 3.57798003e-02, ...,\n",
       "          0.00000000e+00, 2.78910231e-02, 5.21438718e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 4.43487652e-02, ...,\n",
       "          0.00000000e+00, 3.45349349e-02, 3.97345945e-02],\n",
       "         [0.00000000e+00, 0.00000000e+00, 8.18441343e-03, ...,\n",
       "          0.00000000e+00, 1.72152519e-02, 1.98029168e-03]],\n",
       "\n",
       "        [[0.00000000e+00, 2.49323845e-02, 1.89157594e-02, ...,\n",
       "          0.00000000e+00, 3.01625673e-02, 3.80399637e-03],\n",
       "         [0.00000000e+00, 2.80138627e-02, 3.92547324e-02, ...,\n",
       "          0.00000000e+00, 6.42588288e-02, 9.42322891e-03],\n",
       "         [0.00000000e+00, 4.16189544e-02, 2.89784409e-02, ...,\n",
       "          0.00000000e+00, 5.08961380e-02, 1.69905741e-02],\n",
       "         ...,\n",
       "         [0.00000000e+00, 4.35544364e-02, 2.20583640e-02, ...,\n",
       "          0.00000000e+00, 5.66324592e-02, 1.99431982e-02],\n",
       "         [0.00000000e+00, 1.14934770e-02, 2.62723695e-02, ...,\n",
       "          0.00000000e+00, 3.84076461e-02, 3.19191329e-02],\n",
       "         [0.00000000e+00, 8.54388438e-03, 0.00000000e+00, ...,\n",
       "          0.00000000e+00, 1.62717272e-02, 1.83311645e-02]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.joint_entropy(output_layer[-1],output_layer[0])\n",
    "output_layer[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MI_x=np.zeros(16)\n",
    "MI_y=np.zeros(16)\n",
    "for i in range(16):\n",
    "    MI_x[i] = model.calculate_MI(output_layer[-2],output_layer[i])\n",
    "    MI_y[i] = model.calculate_MI(output_layer[i],output_layer[-1])\n",
    "MI_xy = np.vstack((MI_x,MI_y))\n",
    "MI_xy = MI_xy.reshape([1,2,16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MI_sample = np.zeros([1,2,16])\n",
    "MI_sample = np.vstack((MI_sample,MI_xy))\n",
    "MI_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.flip(MI_x))\n",
    "#plt.plot(np.flip(MI_y))\n",
    "print(MI_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch = x_train[0:256,]\n",
    "output_layer1 = model(x_batch)[0]\n",
    "#dis_matrix\n",
    "dist = tf.norm(output_layer1[:,None]-output_layer1,axis=2)\n",
    "dist = dist/tf.math.reduce_max(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gram_matrix with the kernel\n",
    "sigma = tf.reduce_mean(tf.sort(dist)[0][0:10])\n",
    "k = tf.exp(-dist**2/sigma**2)\n",
    "k = k/tf.linalg.trace(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entropy\n",
    "alpha = 1.01\n",
    "eigv = tf.abs(tf.linalg.eigh(k)[0])\n",
    "eig_pow = eigv**alpha\n",
    "entropy = (1/(1-alpha))*np.math.log2(tf.reduce_sum(eig_pow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16()\n",
    "#model.build((1,32, 32, 3))\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X_train, X_test):\n",
    "\n",
    "    # this function normalize inputs for zero mean and unit variance\n",
    "    # it is used when training a model.\n",
    "    # Input: training set and test set\n",
    "    # Output: normalized training set and test set according to the trianing set statistics.\n",
    "    X_train = X_train / 255.\n",
    "    X_test = X_test / 255.\n",
    "\n",
    "    mean = np.mean(X_train, axis=(0, 1, 2, 3))\n",
    "    std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "    print('mean:', mean, 'std:', std)\n",
    "    X_train = (X_train - mean) / (std + 1e-7)\n",
    "    X_test = (X_test - mean) / (std + 1e-7)\n",
    "    return X_train, X_test\n",
    "\n",
    "\n",
    "\n",
    "def prepare_cifar(x, y):\n",
    "\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    y = tf.cast(y, tf.int32)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.4733630004850874 std: 0.25156892506322026\n",
      "x_train_shape:  (50000, 32, 32, 3)\n",
      "y_train_shape:  (50000, 10)\n",
      "x_test_shape:  (10000, 32, 32, 3)\n",
      "y_test_shape:  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "(x_train,y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "x_train, x_test = normalize(x_train, x_test)\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "print('x_train_shape: ',x_train.shape) \n",
    "print('y_train_shape: ',y_train.shape)\n",
    "print('x_test_shape: ',x_test.shape) \n",
    "print('y_test_shape: ',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n"
     ]
    }
   ],
   "source": [
    "train_loader = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
    "train_loader = train_loader.map(prepare_cifar).shuffle(50000).batch(256)\n",
    "test_loader = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_loader = test_loader.map(prepare_cifar).shuffle(10000).batch(256)\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=666\n",
    "plt.imshow(x_train[i,])\n",
    "model(x_train[i:i+128,])[0]\n",
    "#print('predict: ',np.argmax(model(x_train[i:i+1,])[0]))\n",
    "#print('ground truth: ', y_train[i])\n",
    "#type(x_train[0:1,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.Adam(learning_rate=1e-4)\n",
    "loss_object = tf.keras.losses.CategoricalCrossentropy()\n",
    "train_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "test_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "train_avg_loss = tf.keras.metrics.Mean('train_avg_loss', dtype=tf.float32)\n",
    "test_avg_loss = tf.keras.metrics.Mean('test_avg_loss', dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x_train,y_train):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_train_pre = model(x_train,training=True)\n",
    "        loss_train = loss_object(y_train,y_train_pre[0])\n",
    "    grads = tape.gradient(loss_train, model.trainable_variables)\n",
    "    grads = [ tf.clip_by_norm(g, 15) for g in grads]\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    train_avg_loss(loss_train)\n",
    "    train_accuracy(y_train, y_train_pre[0])\n",
    "\n",
    "@tf.function\n",
    "def test_step(x_test,y_test):\n",
    "    y_test_pre = model(x_test,training=False)\n",
    "    loss_test =loss_object(y_test,y_test_pre[0])\n",
    "    test_avg_loss(loss_test)\n",
    "    test_accuracy(y_test, y_test_pre[0])\n",
    "\n",
    "@tf.function\n",
    "def calculate_MI(x_train,y_train):\n",
    "    output = model(x_train,training=False)\n",
    "    output.append(x_train)\n",
    "    output.append(y_train)\n",
    "    MI_x=np.zeros(16)\n",
    "    MI_y=np.zeros(16)\n",
    "    for i in range(16):\n",
    "        MI_x[i] = model.calculate_MI(output_layer[-2],output_layer[i])\n",
    "        MI_y[i] = model.calculate_MI(output_layer[i],output_layer[-1])\n",
    "    MI_xy = np.vstack((MI_x,MI_y))\n",
    "    return MI_xy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train_loss: 3.06416,train_acc:11.260%,test_loss: 2.56917,test_acc: 9.490%\n",
      "Epoch: 1, train_loss: 2.53235,train_acc:15.314%,test_loss: 3.04992,test_acc: 11.210%\n",
      "Epoch: 2, train_loss: 2.26782,train_acc:18.416%,test_loss: 2.75601,test_acc: 11.670%\n",
      "Epoch: 3, train_loss: 2.13610,train_acc:21.226%,test_loss: 2.56713,test_acc: 15.150%\n",
      "Epoch: 4, train_loss: 2.03234,train_acc:24.290%,test_loss: 2.24048,test_acc: 18.980%\n",
      "Epoch: 5, train_loss: 1.93470,train_acc:27.172%,test_loss: 2.33156,test_acc: 22.650%\n",
      "Epoch: 6, train_loss: 1.86103,train_acc:30.002%,test_loss: 2.40723,test_acc: 23.990%\n",
      "Epoch: 7, train_loss: 1.78767,train_acc:33.018%,test_loss: 2.25724,test_acc: 26.090%\n",
      "Epoch: 8, train_loss: 1.70947,train_acc:36.424%,test_loss: 3.72538,test_acc: 26.470%\n",
      "Epoch: 9, train_loss: 1.64998,train_acc:38.968%,test_loss: 4.41907,test_acc: 27.270%\n",
      "Epoch: 10, train_loss: 1.58531,train_acc:41.684%,test_loss: 2.20651,test_acc: 29.960%\n",
      "Epoch: 11, train_loss: 1.52194,train_acc:44.620%,test_loss: 2.74501,test_acc: 31.790%\n",
      "Epoch: 12, train_loss: 1.45235,train_acc:47.442%,test_loss: 3.16881,test_acc: 31.010%\n",
      "Epoch: 13, train_loss: 1.39741,train_acc:49.862%,test_loss: 10.66112,test_acc: 30.710%\n",
      "Epoch: 14, train_loss: 1.34535,train_acc:52.116%,test_loss: 3.02803,test_acc: 32.350%\n",
      "Epoch: 15, train_loss: 1.28065,train_acc:54.858%,test_loss: 2.40807,test_acc: 37.840%\n",
      "Epoch: 16, train_loss: 1.23382,train_acc:56.992%,test_loss: 2.41510,test_acc: 38.040%\n",
      "Epoch: 17, train_loss: 1.17863,train_acc:59.010%,test_loss: 2.71719,test_acc: 40.720%\n",
      "Epoch: 18, train_loss: 1.12792,train_acc:61.244%,test_loss: 1.98101,test_acc: 47.900%\n",
      "Epoch: 19, train_loss: 1.07960,train_acc:63.238%,test_loss: 1.87052,test_acc: 49.890%\n",
      "Epoch: 20, train_loss: 1.04101,train_acc:64.480%,test_loss: 1.90571,test_acc: 53.360%\n",
      "Epoch: 21, train_loss: 0.98933,train_acc:66.544%,test_loss: 1.74438,test_acc: 53.590%\n",
      "Epoch: 22, train_loss: 0.95476,train_acc:67.888%,test_loss: 1.59324,test_acc: 58.030%\n",
      "Epoch: 23, train_loss: 0.90842,train_acc:69.694%,test_loss: 1.65641,test_acc: 57.370%\n",
      "Epoch: 24, train_loss: 0.87297,train_acc:70.962%,test_loss: 1.35785,test_acc: 63.270%\n",
      "Epoch: 25, train_loss: 0.83315,train_acc:72.468%,test_loss: 1.18512,test_acc: 65.830%\n",
      "Epoch: 26, train_loss: 0.80379,train_acc:73.744%,test_loss: 1.23404,test_acc: 66.160%\n",
      "Epoch: 27, train_loss: 0.77497,train_acc:74.900%,test_loss: 1.21142,test_acc: 68.480%\n",
      "Epoch: 28, train_loss: 0.73810,train_acc:76.016%,test_loss: 1.26884,test_acc: 66.140%\n",
      "Epoch: 29, train_loss: 0.71207,train_acc:76.842%,test_loss: 1.23978,test_acc: 66.250%\n",
      "Epoch: 30, train_loss: 0.68711,train_acc:77.968%,test_loss: 0.92379,test_acc: 72.650%\n",
      "Epoch: 31, train_loss: 0.65377,train_acc:78.862%,test_loss: 1.07143,test_acc: 70.510%\n",
      "Epoch: 32, train_loss: 0.63226,train_acc:79.750%,test_loss: 0.98459,test_acc: 72.060%\n",
      "Epoch: 33, train_loss: 0.61211,train_acc:80.630%,test_loss: 0.88414,test_acc: 74.880%\n",
      "Epoch: 34, train_loss: 0.59355,train_acc:81.006%,test_loss: 0.89733,test_acc: 74.900%\n",
      "Epoch: 35, train_loss: 0.56821,train_acc:81.836%,test_loss: 0.87122,test_acc: 75.790%\n",
      "Epoch: 36, train_loss: 0.54641,train_acc:82.598%,test_loss: 0.91963,test_acc: 75.030%\n",
      "Epoch: 37, train_loss: 0.53311,train_acc:83.100%,test_loss: 0.85301,test_acc: 76.770%\n",
      "Epoch: 38, train_loss: 0.51949,train_acc:83.488%,test_loss: 0.83980,test_acc: 76.730%\n",
      "Epoch: 39, train_loss: 0.49572,train_acc:84.330%,test_loss: 0.79115,test_acc: 77.670%\n",
      "Epoch: 40, train_loss: 0.47531,train_acc:85.078%,test_loss: 0.83320,test_acc: 77.450%\n",
      "Epoch: 41, train_loss: 0.46316,train_acc:85.328%,test_loss: 0.86919,test_acc: 77.430%\n",
      "Epoch: 42, train_loss: 0.44821,train_acc:86.046%,test_loss: 0.92344,test_acc: 76.240%\n",
      "Epoch: 43, train_loss: 0.42948,train_acc:86.646%,test_loss: 0.83441,test_acc: 77.960%\n",
      "Epoch: 44, train_loss: 0.41816,train_acc:86.986%,test_loss: 0.80717,test_acc: 79.260%\n",
      "Epoch: 45, train_loss: 0.40671,train_acc:87.308%,test_loss: 0.76565,test_acc: 79.430%\n",
      "Epoch: 46, train_loss: 0.38669,train_acc:87.820%,test_loss: 0.77745,test_acc: 79.830%\n",
      "Epoch: 47, train_loss: 0.37704,train_acc:88.244%,test_loss: 0.79299,test_acc: 79.770%\n",
      "Epoch: 48, train_loss: 0.36544,train_acc:88.642%,test_loss: 0.70238,test_acc: 81.540%\n",
      "Epoch: 49, train_loss: 0.35349,train_acc:88.854%,test_loss: 0.76481,test_acc: 80.540%\n",
      "Epoch: 50, train_loss: 0.33647,train_acc:89.450%,test_loss: 0.79455,test_acc: 80.280%\n",
      "Epoch: 51, train_loss: 0.33098,train_acc:89.792%,test_loss: 0.77518,test_acc: 80.590%\n",
      "Epoch: 52, train_loss: 0.31473,train_acc:90.178%,test_loss: 0.77214,test_acc: 80.470%\n",
      "Epoch: 53, train_loss: 0.31043,train_acc:90.330%,test_loss: 0.77272,test_acc: 80.400%\n",
      "Epoch: 54, train_loss: 0.29612,train_acc:90.768%,test_loss: 0.78525,test_acc: 81.080%\n",
      "Epoch: 55, train_loss: 0.29093,train_acc:90.948%,test_loss: 0.74594,test_acc: 81.280%\n",
      "Epoch: 56, train_loss: 0.27489,train_acc:91.496%,test_loss: 0.72518,test_acc: 81.900%\n",
      "Epoch: 57, train_loss: 0.26825,train_acc:91.666%,test_loss: 0.69354,test_acc: 82.550%\n",
      "Epoch: 58, train_loss: 0.25963,train_acc:92.092%,test_loss: 0.74434,test_acc: 82.250%\n",
      "Epoch: 59, train_loss: 0.25141,train_acc:92.216%,test_loss: 0.77133,test_acc: 81.840%\n",
      "Epoch: 60, train_loss: 0.24682,train_acc:92.428%,test_loss: 0.74578,test_acc: 82.430%\n",
      "Epoch: 61, train_loss: 0.23826,train_acc:92.704%,test_loss: 0.80288,test_acc: 81.440%\n",
      "Epoch: 62, train_loss: 0.23669,train_acc:92.828%,test_loss: 0.73217,test_acc: 82.280%\n",
      "Epoch: 63, train_loss: 0.22186,train_acc:93.190%,test_loss: 0.73699,test_acc: 82.610%\n",
      "Epoch: 64, train_loss: 0.21620,train_acc:93.314%,test_loss: 0.81589,test_acc: 81.180%\n",
      "Epoch: 65, train_loss: 0.21207,train_acc:93.404%,test_loss: 0.82590,test_acc: 81.280%\n",
      "Epoch: 66, train_loss: 0.20679,train_acc:93.778%,test_loss: 0.75225,test_acc: 82.400%\n",
      "Epoch: 67, train_loss: 0.20338,train_acc:93.782%,test_loss: 0.76183,test_acc: 82.520%\n",
      "Epoch: 68, train_loss: 0.19310,train_acc:94.114%,test_loss: 0.74273,test_acc: 82.890%\n",
      "Epoch: 69, train_loss: 0.19250,train_acc:94.004%,test_loss: 0.76524,test_acc: 82.780%\n",
      "Epoch: 70, train_loss: 0.17865,train_acc:94.546%,test_loss: 0.73106,test_acc: 83.510%\n",
      "Epoch: 71, train_loss: 0.17440,train_acc:94.702%,test_loss: 0.71907,test_acc: 83.680%\n",
      "Epoch: 72, train_loss: 0.17045,train_acc:94.604%,test_loss: 0.81285,test_acc: 81.560%\n",
      "Epoch: 73, train_loss: 0.16622,train_acc:94.882%,test_loss: 0.73781,test_acc: 83.340%\n",
      "Epoch: 74, train_loss: 0.16128,train_acc:95.150%,test_loss: 0.71884,test_acc: 83.540%\n",
      "Epoch: 75, train_loss: 0.15666,train_acc:95.214%,test_loss: 0.74046,test_acc: 83.500%\n",
      "Epoch: 76, train_loss: 0.15583,train_acc:95.244%,test_loss: 0.75234,test_acc: 83.410%\n",
      "Epoch: 77, train_loss: 0.15332,train_acc:95.356%,test_loss: 0.74368,test_acc: 83.390%\n",
      "Epoch: 78, train_loss: 0.14466,train_acc:95.740%,test_loss: 0.79669,test_acc: 82.730%\n",
      "Epoch: 79, train_loss: 0.14185,train_acc:95.754%,test_loss: 0.72290,test_acc: 83.830%\n",
      "Epoch: 80, train_loss: 0.14093,train_acc:95.718%,test_loss: 0.78680,test_acc: 83.230%\n",
      "Epoch: 81, train_loss: 0.13905,train_acc:95.852%,test_loss: 0.78218,test_acc: 83.240%\n",
      "Epoch: 82, train_loss: 0.13649,train_acc:95.798%,test_loss: 0.84089,test_acc: 82.620%\n",
      "Epoch: 83, train_loss: 0.13421,train_acc:95.956%,test_loss: 0.77732,test_acc: 83.260%\n",
      "Epoch: 84, train_loss: 0.12633,train_acc:96.190%,test_loss: 0.78603,test_acc: 83.280%\n",
      "Epoch: 85, train_loss: 0.11976,train_acc:96.492%,test_loss: 0.78776,test_acc: 84.030%\n",
      "Epoch: 86, train_loss: 0.11897,train_acc:96.416%,test_loss: 0.83223,test_acc: 82.720%\n",
      "Epoch: 87, train_loss: 0.12020,train_acc:96.394%,test_loss: 0.77619,test_acc: 83.800%\n",
      "Epoch: 88, train_loss: 0.11979,train_acc:96.452%,test_loss: 0.78324,test_acc: 83.840%\n",
      "Epoch: 89, train_loss: 0.11315,train_acc:96.554%,test_loss: 0.79681,test_acc: 83.370%\n",
      "Epoch: 90, train_loss: 0.10574,train_acc:96.788%,test_loss: 0.83141,test_acc: 83.070%\n",
      "Epoch: 91, train_loss: 0.11602,train_acc:96.586%,test_loss: 0.80642,test_acc: 83.900%\n",
      "Epoch: 92, train_loss: 0.10979,train_acc:96.704%,test_loss: 0.76799,test_acc: 84.360%\n",
      "Epoch: 93, train_loss: 0.10815,train_acc:96.710%,test_loss: 0.78720,test_acc: 83.880%\n",
      "Epoch: 94, train_loss: 0.10282,train_acc:96.880%,test_loss: 0.78617,test_acc: 84.440%\n",
      "Epoch: 95, train_loss: 0.10051,train_acc:97.078%,test_loss: 0.81473,test_acc: 83.590%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 96, train_loss: 0.10010,train_acc:97.008%,test_loss: 0.79121,test_acc: 84.430%\n",
      "Epoch: 97, train_loss: 0.09588,train_acc:97.124%,test_loss: 0.79411,test_acc: 84.210%\n",
      "Epoch: 98, train_loss: 0.09454,train_acc:97.130%,test_loss: 0.84471,test_acc: 83.860%\n",
      "Epoch: 99, train_loss: 0.09912,train_acc:97.062%,test_loss: 0.80681,test_acc: 83.940%\n",
      "Epoch: 100, train_loss: 0.09052,train_acc:97.316%,test_loss: 0.82745,test_acc: 83.960%\n",
      "Epoch: 101, train_loss: 0.08729,train_acc:97.444%,test_loss: 0.81490,test_acc: 84.320%\n",
      "Epoch: 102, train_loss: 0.08845,train_acc:97.352%,test_loss: 0.79912,test_acc: 84.120%\n",
      "Epoch: 103, train_loss: 0.08723,train_acc:97.426%,test_loss: 0.83031,test_acc: 83.980%\n",
      "Epoch: 104, train_loss: 0.08868,train_acc:97.378%,test_loss: 0.78167,test_acc: 84.400%\n",
      "Epoch: 105, train_loss: 0.08572,train_acc:97.386%,test_loss: 0.80511,test_acc: 84.250%\n",
      "Epoch: 106, train_loss: 0.07957,train_acc:97.620%,test_loss: 0.78848,test_acc: 84.100%\n",
      "Epoch: 107, train_loss: 0.08423,train_acc:97.508%,test_loss: 0.80243,test_acc: 84.720%\n",
      "Epoch: 108, train_loss: 0.08569,train_acc:97.434%,test_loss: 0.80042,test_acc: 85.040%\n",
      "Epoch: 109, train_loss: 0.08108,train_acc:97.668%,test_loss: 0.87415,test_acc: 83.950%\n",
      "Epoch: 110, train_loss: 0.08365,train_acc:97.500%,test_loss: 0.82590,test_acc: 84.590%\n",
      "Epoch: 111, train_loss: 0.08217,train_acc:97.598%,test_loss: 0.85708,test_acc: 84.280%\n",
      "Epoch: 112, train_loss: 0.07025,train_acc:97.876%,test_loss: 0.87539,test_acc: 84.250%\n",
      "Epoch: 113, train_loss: 0.07474,train_acc:97.788%,test_loss: 0.82713,test_acc: 84.330%\n",
      "Epoch: 114, train_loss: 0.07520,train_acc:97.798%,test_loss: 0.79466,test_acc: 84.650%\n",
      "Epoch: 115, train_loss: 0.07737,train_acc:97.736%,test_loss: 0.79431,test_acc: 85.100%\n",
      "Epoch: 116, train_loss: 0.07161,train_acc:97.868%,test_loss: 0.77620,test_acc: 85.180%\n",
      "Epoch: 117, train_loss: 0.07117,train_acc:97.878%,test_loss: 0.83446,test_acc: 84.600%\n",
      "Epoch: 118, train_loss: 0.07054,train_acc:97.992%,test_loss: 0.77149,test_acc: 85.270%\n",
      "Epoch: 119, train_loss: 0.07058,train_acc:97.948%,test_loss: 0.80155,test_acc: 85.440%\n",
      "Epoch: 120, train_loss: 0.06697,train_acc:98.028%,test_loss: 0.84929,test_acc: 84.410%\n",
      "Epoch: 121, train_loss: 0.06656,train_acc:97.972%,test_loss: 0.81039,test_acc: 84.750%\n",
      "Epoch: 122, train_loss: 0.06851,train_acc:97.952%,test_loss: 0.81526,test_acc: 85.100%\n",
      "Epoch: 123, train_loss: 0.06413,train_acc:98.162%,test_loss: 0.84617,test_acc: 84.460%\n",
      "Epoch: 124, train_loss: 0.06413,train_acc:98.036%,test_loss: 0.83044,test_acc: 85.150%\n",
      "Epoch: 125, train_loss: 0.06522,train_acc:98.054%,test_loss: 0.81144,test_acc: 85.220%\n",
      "Epoch: 126, train_loss: 0.06454,train_acc:98.066%,test_loss: 0.80458,test_acc: 85.350%\n",
      "Epoch: 127, train_loss: 0.06466,train_acc:98.160%,test_loss: 0.79907,test_acc: 84.990%\n",
      "Epoch: 128, train_loss: 0.06353,train_acc:98.152%,test_loss: 0.81812,test_acc: 84.780%\n",
      "Epoch: 129, train_loss: 0.05923,train_acc:98.222%,test_loss: 0.81880,test_acc: 84.770%\n",
      "Epoch: 130, train_loss: 0.06190,train_acc:98.234%,test_loss: 0.82199,test_acc: 85.120%\n",
      "Epoch: 131, train_loss: 0.06344,train_acc:98.186%,test_loss: 0.85340,test_acc: 84.660%\n",
      "Epoch: 132, train_loss: 0.06213,train_acc:98.192%,test_loss: 0.85370,test_acc: 85.080%\n",
      "Epoch: 133, train_loss: 0.05863,train_acc:98.268%,test_loss: 0.80216,test_acc: 84.940%\n",
      "Epoch: 134, train_loss: 0.05570,train_acc:98.308%,test_loss: 0.81237,test_acc: 85.180%\n",
      "Epoch: 135, train_loss: 0.05865,train_acc:98.272%,test_loss: 0.83029,test_acc: 84.620%\n",
      "Epoch: 136, train_loss: 0.06065,train_acc:98.270%,test_loss: 0.83303,test_acc: 84.840%\n",
      "Epoch: 137, train_loss: 0.05512,train_acc:98.346%,test_loss: 0.81727,test_acc: 84.880%\n",
      "Epoch: 138, train_loss: 0.05380,train_acc:98.334%,test_loss: 0.83283,test_acc: 85.240%\n",
      "Epoch: 139, train_loss: 0.05378,train_acc:98.410%,test_loss: 0.81883,test_acc: 84.740%\n",
      "Epoch: 140, train_loss: 0.05380,train_acc:98.418%,test_loss: 0.84309,test_acc: 85.180%\n",
      "Epoch: 141, train_loss: 0.05385,train_acc:98.354%,test_loss: 0.80321,test_acc: 85.600%\n",
      "Epoch: 142, train_loss: 0.05064,train_acc:98.562%,test_loss: 0.83780,test_acc: 85.130%\n",
      "Epoch: 143, train_loss: 0.05461,train_acc:98.438%,test_loss: 0.83638,test_acc: 84.790%\n",
      "Epoch: 144, train_loss: 0.04900,train_acc:98.584%,test_loss: 0.81238,test_acc: 85.310%\n",
      "Epoch: 145, train_loss: 0.05074,train_acc:98.476%,test_loss: 0.83162,test_acc: 85.280%\n",
      "Epoch: 146, train_loss: 0.05411,train_acc:98.430%,test_loss: 0.83573,test_acc: 84.800%\n",
      "Epoch: 147, train_loss: 0.05089,train_acc:98.534%,test_loss: 0.84094,test_acc: 85.070%\n",
      "Epoch: 148, train_loss: 0.04738,train_acc:98.646%,test_loss: 0.79208,test_acc: 85.720%\n",
      "Epoch: 149, train_loss: 0.04929,train_acc:98.590%,test_loss: 0.83323,test_acc: 85.140%\n",
      "Epoch: 150, train_loss: 0.05001,train_acc:98.488%,test_loss: 0.84524,test_acc: 85.550%\n",
      "Epoch: 151, train_loss: 0.04951,train_acc:98.510%,test_loss: 0.85715,test_acc: 84.900%\n",
      "Epoch: 152, train_loss: 0.05079,train_acc:98.528%,test_loss: 0.84093,test_acc: 85.240%\n",
      "Epoch: 153, train_loss: 0.04762,train_acc:98.592%,test_loss: 0.83484,test_acc: 85.490%\n",
      "Epoch: 154, train_loss: 0.04751,train_acc:98.602%,test_loss: 0.81593,test_acc: 85.560%\n",
      "Epoch: 155, train_loss: 0.04763,train_acc:98.552%,test_loss: 0.81258,test_acc: 85.470%\n",
      "Epoch: 156, train_loss: 0.05085,train_acc:98.534%,test_loss: 0.85118,test_acc: 84.940%\n",
      "Epoch: 157, train_loss: 0.04776,train_acc:98.584%,test_loss: 0.82657,test_acc: 85.590%\n",
      "Epoch: 158, train_loss: 0.04416,train_acc:98.634%,test_loss: 0.81842,test_acc: 85.770%\n",
      "Epoch: 159, train_loss: 0.04291,train_acc:98.740%,test_loss: 0.81235,test_acc: 85.630%\n",
      "Epoch: 160, train_loss: 0.04608,train_acc:98.718%,test_loss: 0.80951,test_acc: 85.840%\n",
      "Epoch: 161, train_loss: 0.04540,train_acc:98.708%,test_loss: 0.82695,test_acc: 85.540%\n",
      "Epoch: 162, train_loss: 0.04351,train_acc:98.696%,test_loss: 0.83898,test_acc: 85.680%\n",
      "Epoch: 163, train_loss: 0.04152,train_acc:98.800%,test_loss: 0.81366,test_acc: 85.460%\n",
      "Epoch: 164, train_loss: 0.04460,train_acc:98.720%,test_loss: 0.77936,test_acc: 86.430%\n",
      "Epoch: 165, train_loss: 0.04453,train_acc:98.720%,test_loss: 0.80068,test_acc: 85.760%\n",
      "Epoch: 166, train_loss: 0.04399,train_acc:98.720%,test_loss: 0.85165,test_acc: 85.540%\n",
      "Epoch: 167, train_loss: 0.04617,train_acc:98.624%,test_loss: 0.89315,test_acc: 85.140%\n",
      "Epoch: 168, train_loss: 0.04296,train_acc:98.760%,test_loss: 0.78982,test_acc: 85.710%\n",
      "Epoch: 169, train_loss: 0.04075,train_acc:98.836%,test_loss: 0.85075,test_acc: 85.550%\n",
      "Epoch: 170, train_loss: 0.04242,train_acc:98.754%,test_loss: 0.80234,test_acc: 85.930%\n",
      "Epoch: 171, train_loss: 0.03763,train_acc:98.910%,test_loss: 0.85343,test_acc: 85.320%\n",
      "Epoch: 172, train_loss: 0.04106,train_acc:98.844%,test_loss: 0.84274,test_acc: 85.340%\n",
      "Epoch: 173, train_loss: 0.04109,train_acc:98.780%,test_loss: 0.83091,test_acc: 85.500%\n",
      "Epoch: 174, train_loss: 0.04253,train_acc:98.704%,test_loss: 0.81554,test_acc: 85.660%\n",
      "Epoch: 175, train_loss: 0.03713,train_acc:98.904%,test_loss: 0.84372,test_acc: 85.550%\n",
      "Epoch: 176, train_loss: 0.04042,train_acc:98.822%,test_loss: 0.84373,test_acc: 85.950%\n",
      "Epoch: 177, train_loss: 0.03720,train_acc:98.914%,test_loss: 0.84109,test_acc: 85.520%\n",
      "Epoch: 178, train_loss: 0.03621,train_acc:98.950%,test_loss: 0.85615,test_acc: 85.280%\n",
      "Epoch: 179, train_loss: 0.03782,train_acc:98.884%,test_loss: 0.87891,test_acc: 85.800%\n",
      "Epoch: 180, train_loss: 0.03849,train_acc:98.852%,test_loss: 0.81806,test_acc: 85.800%\n",
      "Epoch: 181, train_loss: 0.03917,train_acc:98.836%,test_loss: 0.88040,test_acc: 84.970%\n",
      "Epoch: 182, train_loss: 0.03867,train_acc:98.840%,test_loss: 0.86271,test_acc: 85.250%\n",
      "Epoch: 183, train_loss: 0.03748,train_acc:98.936%,test_loss: 0.81810,test_acc: 86.130%\n",
      "Epoch: 184, train_loss: 0.03571,train_acc:98.946%,test_loss: 0.85643,test_acc: 85.670%\n",
      "Epoch: 185, train_loss: 0.03457,train_acc:98.990%,test_loss: 0.85027,test_acc: 85.760%\n",
      "Epoch: 186, train_loss: 0.03950,train_acc:98.836%,test_loss: 0.83479,test_acc: 85.680%\n",
      "Epoch: 187, train_loss: 0.04147,train_acc:98.780%,test_loss: 0.78284,test_acc: 86.000%\n",
      "Epoch: 188, train_loss: 0.03426,train_acc:98.948%,test_loss: 0.82314,test_acc: 86.240%\n",
      "Epoch: 189, train_loss: 0.03475,train_acc:99.034%,test_loss: 0.82043,test_acc: 85.600%\n",
      "Epoch: 190, train_loss: 0.03501,train_acc:98.970%,test_loss: 0.84893,test_acc: 85.570%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 191, train_loss: 0.04087,train_acc:98.826%,test_loss: 0.88746,test_acc: 85.530%\n",
      "Epoch: 192, train_loss: 0.03727,train_acc:98.888%,test_loss: 0.82398,test_acc: 86.030%\n",
      "Epoch: 193, train_loss: 0.03365,train_acc:98.980%,test_loss: 0.79712,test_acc: 86.330%\n",
      "Epoch: 194, train_loss: 0.03503,train_acc:98.978%,test_loss: 0.85911,test_acc: 85.890%\n",
      "Epoch: 195, train_loss: 0.03370,train_acc:98.962%,test_loss: 0.82572,test_acc: 85.970%\n",
      "Epoch: 196, train_loss: 0.03397,train_acc:99.036%,test_loss: 0.87695,test_acc: 85.330%\n",
      "Epoch: 197, train_loss: 0.03178,train_acc:99.116%,test_loss: 0.85067,test_acc: 85.520%\n",
      "Epoch: 198, train_loss: 0.03682,train_acc:98.938%,test_loss: 0.88616,test_acc: 85.640%\n",
      "Epoch: 199, train_loss: 0.03572,train_acc:98.966%,test_loss: 0.81228,test_acc: 85.760%\n",
      "Epoch: 200, train_loss: 0.03624,train_acc:98.946%,test_loss: 0.81789,test_acc: 85.990%\n",
      "Epoch: 201, train_loss: 0.03413,train_acc:98.938%,test_loss: 0.87501,test_acc: 85.400%\n",
      "Epoch: 202, train_loss: 0.03060,train_acc:99.120%,test_loss: 0.85782,test_acc: 85.650%\n",
      "Epoch: 203, train_loss: 0.03414,train_acc:99.004%,test_loss: 0.90823,test_acc: 85.570%\n",
      "Epoch: 204, train_loss: 0.03269,train_acc:99.058%,test_loss: 0.87916,test_acc: 85.850%\n",
      "Epoch: 205, train_loss: 0.03794,train_acc:98.944%,test_loss: 0.83486,test_acc: 85.520%\n",
      "Epoch: 206, train_loss: 0.03130,train_acc:99.094%,test_loss: 0.87218,test_acc: 85.660%\n",
      "Epoch: 207, train_loss: 0.03151,train_acc:99.094%,test_loss: 0.86329,test_acc: 85.720%\n",
      "Epoch: 208, train_loss: 0.02919,train_acc:99.182%,test_loss: 0.85019,test_acc: 85.990%\n",
      "Epoch: 209, train_loss: 0.02990,train_acc:99.116%,test_loss: 0.82097,test_acc: 86.320%\n",
      "Epoch: 210, train_loss: 0.02921,train_acc:99.146%,test_loss: 0.83896,test_acc: 86.320%\n",
      "Epoch: 211, train_loss: 0.03273,train_acc:99.034%,test_loss: 0.86503,test_acc: 86.170%\n",
      "Epoch: 212, train_loss: 0.03011,train_acc:99.112%,test_loss: 0.84219,test_acc: 86.170%\n",
      "Epoch: 213, train_loss: 0.03174,train_acc:99.116%,test_loss: 0.86580,test_acc: 85.660%\n",
      "Epoch: 214, train_loss: 0.03094,train_acc:99.084%,test_loss: 0.87302,test_acc: 85.870%\n",
      "Epoch: 215, train_loss: 0.03175,train_acc:99.110%,test_loss: 0.84025,test_acc: 85.940%\n",
      "Epoch: 216, train_loss: 0.02952,train_acc:99.170%,test_loss: 0.87603,test_acc: 85.740%\n",
      "Epoch: 217, train_loss: 0.03012,train_acc:99.154%,test_loss: 0.77870,test_acc: 86.390%\n",
      "Epoch: 218, train_loss: 0.03073,train_acc:99.124%,test_loss: 0.81747,test_acc: 86.020%\n",
      "Epoch: 219, train_loss: 0.03160,train_acc:99.068%,test_loss: 0.80193,test_acc: 85.870%\n",
      "Epoch: 220, train_loss: 0.03018,train_acc:99.096%,test_loss: 0.83241,test_acc: 85.740%\n",
      "Epoch: 221, train_loss: 0.02811,train_acc:99.180%,test_loss: 0.87533,test_acc: 85.310%\n",
      "Epoch: 222, train_loss: 0.02905,train_acc:99.144%,test_loss: 0.85030,test_acc: 86.440%\n",
      "Epoch: 223, train_loss: 0.02820,train_acc:99.164%,test_loss: 0.90890,test_acc: 85.470%\n",
      "Epoch: 224, train_loss: 0.02562,train_acc:99.194%,test_loss: 0.85406,test_acc: 85.840%\n",
      "Epoch: 225, train_loss: 0.02560,train_acc:99.234%,test_loss: 0.80277,test_acc: 86.560%\n",
      "Epoch: 226, train_loss: 0.02916,train_acc:99.174%,test_loss: 0.86321,test_acc: 86.020%\n",
      "Epoch: 227, train_loss: 0.03257,train_acc:99.072%,test_loss: 0.84286,test_acc: 86.410%\n",
      "Epoch: 228, train_loss: 0.02948,train_acc:99.144%,test_loss: 0.84404,test_acc: 86.590%\n",
      "Epoch: 229, train_loss: 0.03125,train_acc:99.084%,test_loss: 0.81024,test_acc: 86.470%\n",
      "Epoch: 230, train_loss: 0.02915,train_acc:99.200%,test_loss: 0.80524,test_acc: 86.590%\n",
      "Epoch: 231, train_loss: 0.02994,train_acc:99.166%,test_loss: 0.79131,test_acc: 86.560%\n",
      "Epoch: 232, train_loss: 0.02699,train_acc:99.222%,test_loss: 0.83612,test_acc: 86.020%\n",
      "Epoch: 233, train_loss: 0.02803,train_acc:99.182%,test_loss: 0.81367,test_acc: 86.530%\n",
      "Epoch: 234, train_loss: 0.02794,train_acc:99.194%,test_loss: 0.78907,test_acc: 86.570%\n",
      "Epoch: 235, train_loss: 0.02863,train_acc:99.154%,test_loss: 0.85977,test_acc: 85.900%\n",
      "Epoch: 236, train_loss: 0.02544,train_acc:99.266%,test_loss: 0.84981,test_acc: 86.430%\n",
      "Epoch: 237, train_loss: 0.02611,train_acc:99.228%,test_loss: 0.84506,test_acc: 86.240%\n",
      "Epoch: 238, train_loss: 0.02831,train_acc:99.190%,test_loss: 0.85187,test_acc: 85.990%\n",
      "Epoch: 239, train_loss: 0.02223,train_acc:99.314%,test_loss: 0.83925,test_acc: 86.420%\n",
      "Epoch: 240, train_loss: 0.02386,train_acc:99.308%,test_loss: 0.87752,test_acc: 86.110%\n",
      "Epoch: 241, train_loss: 0.02765,train_acc:99.174%,test_loss: 0.86465,test_acc: 85.870%\n",
      "Epoch: 242, train_loss: 0.02845,train_acc:99.148%,test_loss: 0.85137,test_acc: 86.250%\n",
      "Epoch: 243, train_loss: 0.02613,train_acc:99.210%,test_loss: 0.85760,test_acc: 86.190%\n",
      "Epoch: 244, train_loss: 0.02544,train_acc:99.288%,test_loss: 0.81198,test_acc: 86.760%\n",
      "Epoch: 245, train_loss: 0.02574,train_acc:99.282%,test_loss: 0.81603,test_acc: 86.560%\n",
      "Epoch: 246, train_loss: 0.02671,train_acc:99.270%,test_loss: 0.82523,test_acc: 86.070%\n",
      "Epoch: 247, train_loss: 0.02326,train_acc:99.342%,test_loss: 0.84683,test_acc: 86.170%\n",
      "Epoch: 248, train_loss: 0.02557,train_acc:99.258%,test_loss: 0.85200,test_acc: 86.340%\n",
      "Epoch: 249, train_loss: 0.02665,train_acc:99.224%,test_loss: 0.88387,test_acc: 85.640%\n",
      "Epoch: 250, train_loss: 0.02533,train_acc:99.246%,test_loss: 0.87830,test_acc: 85.500%\n",
      "Epoch: 251, train_loss: 0.02582,train_acc:99.252%,test_loss: 0.83604,test_acc: 86.120%\n",
      "Epoch: 252, train_loss: 0.02318,train_acc:99.324%,test_loss: 0.86942,test_acc: 85.990%\n",
      "Epoch: 253, train_loss: 0.02760,train_acc:99.220%,test_loss: 0.85533,test_acc: 86.270%\n",
      "Epoch: 254, train_loss: 0.02580,train_acc:99.284%,test_loss: 0.82085,test_acc: 86.230%\n",
      "Epoch: 255, train_loss: 0.02464,train_acc:99.284%,test_loss: 0.84560,test_acc: 86.050%\n",
      "Epoch: 256, train_loss: 0.02489,train_acc:99.282%,test_loss: 0.83523,test_acc: 85.850%\n",
      "Epoch: 257, train_loss: 0.02507,train_acc:99.264%,test_loss: 0.88501,test_acc: 85.880%\n",
      "Epoch: 258, train_loss: 0.02410,train_acc:99.264%,test_loss: 0.86163,test_acc: 85.950%\n",
      "Epoch: 259, train_loss: 0.02602,train_acc:99.240%,test_loss: 0.86212,test_acc: 85.680%\n",
      "Epoch: 260, train_loss: 0.02239,train_acc:99.332%,test_loss: 0.85132,test_acc: 86.270%\n",
      "Epoch: 261, train_loss: 0.02404,train_acc:99.348%,test_loss: 0.84248,test_acc: 85.940%\n",
      "Epoch: 262, train_loss: 0.02698,train_acc:99.214%,test_loss: 0.87209,test_acc: 86.090%\n",
      "Epoch: 263, train_loss: 0.02361,train_acc:99.292%,test_loss: 0.83587,test_acc: 86.350%\n",
      "Epoch: 264, train_loss: 0.02103,train_acc:99.380%,test_loss: 0.84620,test_acc: 86.120%\n",
      "Epoch: 265, train_loss: 0.02306,train_acc:99.368%,test_loss: 0.89802,test_acc: 85.810%\n",
      "Epoch: 266, train_loss: 0.02408,train_acc:99.284%,test_loss: 0.82926,test_acc: 86.750%\n",
      "Epoch: 267, train_loss: 0.02435,train_acc:99.314%,test_loss: 0.81602,test_acc: 86.430%\n",
      "Epoch: 268, train_loss: 0.02306,train_acc:99.324%,test_loss: 0.84227,test_acc: 86.430%\n",
      "Epoch: 269, train_loss: 0.02223,train_acc:99.368%,test_loss: 0.85852,test_acc: 86.730%\n",
      "Epoch: 270, train_loss: 0.02411,train_acc:99.290%,test_loss: 0.92728,test_acc: 86.260%\n",
      "Epoch: 271, train_loss: 0.02287,train_acc:99.356%,test_loss: 0.82542,test_acc: 86.260%\n",
      "Epoch: 272, train_loss: 0.02081,train_acc:99.376%,test_loss: 0.88903,test_acc: 86.440%\n",
      "Epoch: 273, train_loss: 0.02303,train_acc:99.330%,test_loss: 0.85319,test_acc: 86.620%\n",
      "Epoch: 274, train_loss: 0.02064,train_acc:99.380%,test_loss: 0.87782,test_acc: 86.290%\n",
      "Epoch: 275, train_loss: 0.02121,train_acc:99.396%,test_loss: 0.81557,test_acc: 86.520%\n",
      "Epoch: 276, train_loss: 0.02287,train_acc:99.372%,test_loss: 0.87955,test_acc: 86.450%\n",
      "Epoch: 277, train_loss: 0.02267,train_acc:99.360%,test_loss: 0.85405,test_acc: 86.480%\n",
      "Epoch: 278, train_loss: 0.02141,train_acc:99.404%,test_loss: 0.85118,test_acc: 86.740%\n",
      "Epoch: 279, train_loss: 0.02147,train_acc:99.392%,test_loss: 0.81072,test_acc: 86.820%\n",
      "Epoch: 280, train_loss: 0.02427,train_acc:99.320%,test_loss: 0.88370,test_acc: 86.470%\n",
      "Epoch: 281, train_loss: 0.02131,train_acc:99.362%,test_loss: 0.83550,test_acc: 86.730%\n",
      "Epoch: 282, train_loss: 0.02189,train_acc:99.356%,test_loss: 0.87576,test_acc: 86.900%\n",
      "Epoch: 283, train_loss: 0.02058,train_acc:99.372%,test_loss: 0.85470,test_acc: 86.490%\n",
      "Epoch: 284, train_loss: 0.02018,train_acc:99.404%,test_loss: 0.85694,test_acc: 85.920%\n",
      "Epoch: 285, train_loss: 0.02202,train_acc:99.366%,test_loss: 0.84863,test_acc: 86.550%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 286, train_loss: 0.02038,train_acc:99.368%,test_loss: 0.81253,test_acc: 87.050%\n",
      "Epoch: 287, train_loss: 0.01992,train_acc:99.444%,test_loss: 0.81581,test_acc: 86.860%\n",
      "Epoch: 288, train_loss: 0.02189,train_acc:99.328%,test_loss: 0.80652,test_acc: 86.880%\n",
      "Epoch: 289, train_loss: 0.02162,train_acc:99.352%,test_loss: 0.83475,test_acc: 86.420%\n",
      "Epoch: 290, train_loss: 0.02044,train_acc:99.400%,test_loss: 0.85988,test_acc: 86.230%\n",
      "Epoch: 291, train_loss: 0.02025,train_acc:99.386%,test_loss: 0.87819,test_acc: 86.360%\n",
      "Epoch: 292, train_loss: 0.02110,train_acc:99.388%,test_loss: 0.85327,test_acc: 86.480%\n",
      "Epoch: 293, train_loss: 0.02127,train_acc:99.400%,test_loss: 0.86608,test_acc: 86.580%\n",
      "Epoch: 294, train_loss: 0.02181,train_acc:99.382%,test_loss: 0.82972,test_acc: 86.710%\n",
      "Epoch: 295, train_loss: 0.02165,train_acc:99.380%,test_loss: 0.83086,test_acc: 86.560%\n",
      "Epoch: 296, train_loss: 0.01926,train_acc:99.420%,test_loss: 0.83777,test_acc: 86.770%\n",
      "Epoch: 297, train_loss: 0.02003,train_acc:99.428%,test_loss: 0.85978,test_acc: 86.450%\n",
      "Epoch: 298, train_loss: 0.01980,train_acc:99.440%,test_loss: 0.85753,test_acc: 86.880%\n",
      "Epoch: 299, train_loss: 0.02268,train_acc:99.372%,test_loss: 0.82741,test_acc: 86.740%\n",
      "Epoch: 300, train_loss: 0.02219,train_acc:99.358%,test_loss: 0.84039,test_acc: 86.770%\n",
      "Epoch: 301, train_loss: 0.02187,train_acc:99.372%,test_loss: 0.81772,test_acc: 86.960%\n",
      "Epoch: 302, train_loss: 0.01943,train_acc:99.432%,test_loss: 0.84386,test_acc: 86.740%\n",
      "Epoch: 303, train_loss: 0.01829,train_acc:99.490%,test_loss: 0.83284,test_acc: 86.860%\n",
      "Epoch: 304, train_loss: 0.02030,train_acc:99.370%,test_loss: 0.84229,test_acc: 86.760%\n",
      "Epoch: 305, train_loss: 0.02058,train_acc:99.404%,test_loss: 0.83754,test_acc: 87.100%\n",
      "Epoch: 306, train_loss: 0.01961,train_acc:99.424%,test_loss: 0.86541,test_acc: 86.290%\n",
      "Epoch: 307, train_loss: 0.02216,train_acc:99.364%,test_loss: 0.85027,test_acc: 86.530%\n",
      "Epoch: 308, train_loss: 0.01796,train_acc:99.480%,test_loss: 0.83692,test_acc: 86.480%\n",
      "Epoch: 309, train_loss: 0.01968,train_acc:99.440%,test_loss: 0.85455,test_acc: 86.600%\n",
      "Epoch: 310, train_loss: 0.02030,train_acc:99.370%,test_loss: 0.84300,test_acc: 86.390%\n",
      "Epoch: 311, train_loss: 0.02067,train_acc:99.418%,test_loss: 0.84292,test_acc: 86.810%\n",
      "Epoch: 312, train_loss: 0.01973,train_acc:99.398%,test_loss: 0.83325,test_acc: 86.720%\n",
      "Epoch: 313, train_loss: 0.01965,train_acc:99.486%,test_loss: 0.81851,test_acc: 87.130%\n",
      "Epoch: 314, train_loss: 0.01865,train_acc:99.446%,test_loss: 0.85222,test_acc: 86.410%\n",
      "Epoch: 315, train_loss: 0.01892,train_acc:99.446%,test_loss: 0.89450,test_acc: 86.670%\n",
      "Epoch: 316, train_loss: 0.01880,train_acc:99.478%,test_loss: 0.83798,test_acc: 86.410%\n",
      "Epoch: 317, train_loss: 0.02005,train_acc:99.406%,test_loss: 0.83188,test_acc: 86.530%\n",
      "Epoch: 318, train_loss: 0.01967,train_acc:99.422%,test_loss: 0.84799,test_acc: 87.010%\n",
      "Epoch: 319, train_loss: 0.02046,train_acc:99.426%,test_loss: 0.81325,test_acc: 86.860%\n",
      "Epoch: 320, train_loss: 0.01773,train_acc:99.520%,test_loss: 0.82630,test_acc: 86.860%\n",
      "Epoch: 321, train_loss: 0.01614,train_acc:99.556%,test_loss: 0.84405,test_acc: 87.070%\n",
      "Epoch: 322, train_loss: 0.02161,train_acc:99.344%,test_loss: 0.86591,test_acc: 86.860%\n",
      "Epoch: 323, train_loss: 0.01934,train_acc:99.456%,test_loss: 0.86709,test_acc: 86.570%\n",
      "Epoch: 324, train_loss: 0.01783,train_acc:99.466%,test_loss: 0.89001,test_acc: 86.260%\n",
      "Epoch: 325, train_loss: 0.01818,train_acc:99.470%,test_loss: 0.87233,test_acc: 86.460%\n",
      "Epoch: 326, train_loss: 0.01881,train_acc:99.428%,test_loss: 0.89357,test_acc: 86.300%\n",
      "Epoch: 327, train_loss: 0.01862,train_acc:99.460%,test_loss: 0.86895,test_acc: 86.630%\n",
      "Epoch: 328, train_loss: 0.01721,train_acc:99.470%,test_loss: 0.86760,test_acc: 86.740%\n",
      "Epoch: 329, train_loss: 0.01923,train_acc:99.476%,test_loss: 0.84908,test_acc: 87.000%\n",
      "Epoch: 330, train_loss: 0.01841,train_acc:99.466%,test_loss: 0.86736,test_acc: 86.390%\n",
      "Epoch: 331, train_loss: 0.01880,train_acc:99.436%,test_loss: 0.81262,test_acc: 86.900%\n",
      "Epoch: 332, train_loss: 0.01806,train_acc:99.456%,test_loss: 0.84423,test_acc: 86.900%\n",
      "Epoch: 333, train_loss: 0.01592,train_acc:99.528%,test_loss: 0.85347,test_acc: 86.960%\n",
      "Epoch: 334, train_loss: 0.01712,train_acc:99.496%,test_loss: 0.86709,test_acc: 86.560%\n",
      "Epoch: 335, train_loss: 0.01953,train_acc:99.424%,test_loss: 0.83325,test_acc: 86.910%\n",
      "Epoch: 336, train_loss: 0.01660,train_acc:99.534%,test_loss: 0.84627,test_acc: 86.940%\n",
      "Epoch: 337, train_loss: 0.01799,train_acc:99.488%,test_loss: 0.85661,test_acc: 87.110%\n",
      "Epoch: 338, train_loss: 0.01640,train_acc:99.520%,test_loss: 0.83427,test_acc: 86.950%\n",
      "Epoch: 339, train_loss: 0.01754,train_acc:99.526%,test_loss: 0.90171,test_acc: 86.740%\n",
      "Epoch: 340, train_loss: 0.01741,train_acc:99.520%,test_loss: 0.86327,test_acc: 86.740%\n",
      "Epoch: 341, train_loss: 0.01744,train_acc:99.496%,test_loss: 0.88577,test_acc: 86.770%\n",
      "Epoch: 342, train_loss: 0.01788,train_acc:99.492%,test_loss: 0.85635,test_acc: 86.730%\n",
      "Epoch: 343, train_loss: 0.01739,train_acc:99.468%,test_loss: 0.85598,test_acc: 86.870%\n",
      "Epoch: 344, train_loss: 0.01765,train_acc:99.486%,test_loss: 0.84745,test_acc: 86.820%\n",
      "Epoch: 345, train_loss: 0.01982,train_acc:99.406%,test_loss: 0.83077,test_acc: 86.780%\n",
      "Epoch: 346, train_loss: 0.01834,train_acc:99.504%,test_loss: 0.87856,test_acc: 86.560%\n",
      "Epoch: 347, train_loss: 0.01610,train_acc:99.526%,test_loss: 0.80369,test_acc: 87.310%\n",
      "Epoch: 348, train_loss: 0.01891,train_acc:99.424%,test_loss: 0.81341,test_acc: 86.890%\n",
      "Epoch: 349, train_loss: 0.01531,train_acc:99.522%,test_loss: 0.85579,test_acc: 86.800%\n",
      "Epoch: 350, train_loss: 0.01339,train_acc:99.574%,test_loss: 0.85655,test_acc: 87.170%\n",
      "Epoch: 351, train_loss: 0.01743,train_acc:99.508%,test_loss: 0.83242,test_acc: 87.070%\n",
      "Epoch: 352, train_loss: 0.01828,train_acc:99.492%,test_loss: 0.84383,test_acc: 86.840%\n",
      "Epoch: 353, train_loss: 0.01922,train_acc:99.454%,test_loss: 0.82051,test_acc: 87.200%\n",
      "Epoch: 354, train_loss: 0.01653,train_acc:99.518%,test_loss: 0.84267,test_acc: 86.630%\n",
      "Epoch: 355, train_loss: 0.01632,train_acc:99.558%,test_loss: 0.85310,test_acc: 86.830%\n",
      "Epoch: 356, train_loss: 0.01680,train_acc:99.528%,test_loss: 0.84241,test_acc: 86.760%\n",
      "Epoch: 357, train_loss: 0.01722,train_acc:99.518%,test_loss: 0.87835,test_acc: 86.390%\n",
      "Epoch: 358, train_loss: 0.01449,train_acc:99.582%,test_loss: 0.92809,test_acc: 86.550%\n",
      "Epoch: 359, train_loss: 0.01489,train_acc:99.586%,test_loss: 0.85761,test_acc: 86.920%\n",
      "Epoch: 360, train_loss: 0.01684,train_acc:99.516%,test_loss: 0.83638,test_acc: 86.940%\n",
      "Epoch: 361, train_loss: 0.01911,train_acc:99.460%,test_loss: 0.84639,test_acc: 86.740%\n",
      "Epoch: 362, train_loss: 0.01602,train_acc:99.532%,test_loss: 0.82960,test_acc: 86.880%\n",
      "Epoch: 363, train_loss: 0.01711,train_acc:99.530%,test_loss: 0.84599,test_acc: 86.900%\n",
      "Epoch: 364, train_loss: 0.01841,train_acc:99.510%,test_loss: 0.85327,test_acc: 86.690%\n",
      "Epoch: 365, train_loss: 0.01840,train_acc:99.476%,test_loss: 0.84615,test_acc: 86.840%\n",
      "Epoch: 366, train_loss: 0.01427,train_acc:99.572%,test_loss: 0.84881,test_acc: 86.430%\n",
      "Epoch: 367, train_loss: 0.01690,train_acc:99.514%,test_loss: 0.85918,test_acc: 86.650%\n",
      "Epoch: 368, train_loss: 0.01332,train_acc:99.602%,test_loss: 0.89389,test_acc: 86.470%\n",
      "Epoch: 369, train_loss: 0.01512,train_acc:99.568%,test_loss: 0.86490,test_acc: 86.930%\n",
      "Epoch: 370, train_loss: 0.01696,train_acc:99.524%,test_loss: 0.84627,test_acc: 87.090%\n",
      "Epoch: 371, train_loss: 0.01372,train_acc:99.612%,test_loss: 0.87907,test_acc: 86.450%\n",
      "Epoch: 372, train_loss: 0.01604,train_acc:99.556%,test_loss: 0.86833,test_acc: 86.550%\n",
      "Epoch: 373, train_loss: 0.01673,train_acc:99.502%,test_loss: 0.85917,test_acc: 86.530%\n",
      "Epoch: 374, train_loss: 0.01550,train_acc:99.534%,test_loss: 0.88685,test_acc: 86.410%\n",
      "Epoch: 375, train_loss: 0.01603,train_acc:99.546%,test_loss: 0.85799,test_acc: 86.620%\n",
      "Epoch: 376, train_loss: 0.01603,train_acc:99.526%,test_loss: 0.86302,test_acc: 86.540%\n",
      "Epoch: 377, train_loss: 0.01759,train_acc:99.508%,test_loss: 0.81793,test_acc: 87.100%\n",
      "Epoch: 378, train_loss: 0.01618,train_acc:99.538%,test_loss: 0.81956,test_acc: 86.970%\n",
      "Epoch: 379, train_loss: 0.01559,train_acc:99.574%,test_loss: 0.85466,test_acc: 86.730%\n",
      "Epoch: 380, train_loss: 0.01640,train_acc:99.568%,test_loss: 0.83259,test_acc: 87.090%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 381, train_loss: 0.01595,train_acc:99.534%,test_loss: 0.86272,test_acc: 87.100%\n",
      "Epoch: 382, train_loss: 0.01718,train_acc:99.512%,test_loss: 0.83893,test_acc: 87.100%\n",
      "Epoch: 383, train_loss: 0.01445,train_acc:99.582%,test_loss: 0.82378,test_acc: 87.050%\n",
      "Epoch: 384, train_loss: 0.01507,train_acc:99.596%,test_loss: 0.83686,test_acc: 87.380%\n",
      "Epoch: 385, train_loss: 0.01422,train_acc:99.552%,test_loss: 0.83973,test_acc: 87.160%\n",
      "Epoch: 386, train_loss: 0.01372,train_acc:99.606%,test_loss: 0.82353,test_acc: 87.380%\n",
      "Epoch: 387, train_loss: 0.01493,train_acc:99.552%,test_loss: 0.85212,test_acc: 86.910%\n",
      "Epoch: 388, train_loss: 0.01632,train_acc:99.522%,test_loss: 0.87249,test_acc: 86.730%\n",
      "Epoch: 389, train_loss: 0.01494,train_acc:99.596%,test_loss: 0.85814,test_acc: 86.890%\n",
      "Epoch: 390, train_loss: 0.01525,train_acc:99.586%,test_loss: 0.89007,test_acc: 86.650%\n",
      "Epoch: 391, train_loss: 0.01557,train_acc:99.556%,test_loss: 0.86572,test_acc: 86.900%\n",
      "Epoch: 392, train_loss: 0.01594,train_acc:99.552%,test_loss: 0.84782,test_acc: 86.830%\n",
      "Epoch: 393, train_loss: 0.01491,train_acc:99.580%,test_loss: 0.84395,test_acc: 86.960%\n",
      "Epoch: 394, train_loss: 0.01341,train_acc:99.600%,test_loss: 0.82960,test_acc: 87.040%\n",
      "Epoch: 395, train_loss: 0.01657,train_acc:99.556%,test_loss: 0.83300,test_acc: 87.180%\n",
      "Epoch: 396, train_loss: 0.01622,train_acc:99.558%,test_loss: 0.86244,test_acc: 86.750%\n",
      "Epoch: 397, train_loss: 0.01404,train_acc:99.564%,test_loss: 0.78195,test_acc: 87.370%\n",
      "Epoch: 398, train_loss: 0.01430,train_acc:99.582%,test_loss: 0.85429,test_acc: 87.270%\n",
      "Epoch: 399, train_loss: 0.01533,train_acc:99.570%,test_loss: 0.82336,test_acc: 87.110%\n",
      "Epoch: 400, train_loss: 0.01657,train_acc:99.546%,test_loss: 0.86363,test_acc: 86.870%\n",
      "Epoch: 401, train_loss: 0.01587,train_acc:99.574%,test_loss: 0.85633,test_acc: 86.620%\n",
      "Epoch: 402, train_loss: 0.01466,train_acc:99.538%,test_loss: 0.86423,test_acc: 86.650%\n",
      "Epoch: 403, train_loss: 0.01374,train_acc:99.616%,test_loss: 0.85132,test_acc: 86.870%\n",
      "Epoch: 404, train_loss: 0.01472,train_acc:99.576%,test_loss: 0.84040,test_acc: 87.150%\n",
      "Epoch: 405, train_loss: 0.01536,train_acc:99.570%,test_loss: 0.84265,test_acc: 87.060%\n",
      "Epoch: 406, train_loss: 0.01252,train_acc:99.614%,test_loss: 0.82655,test_acc: 87.350%\n",
      "Epoch: 407, train_loss: 0.01386,train_acc:99.598%,test_loss: 0.81066,test_acc: 87.390%\n",
      "Epoch: 408, train_loss: 0.01447,train_acc:99.568%,test_loss: 0.82230,test_acc: 87.250%\n",
      "Epoch: 409, train_loss: 0.01407,train_acc:99.608%,test_loss: 0.84163,test_acc: 87.160%\n",
      "Epoch: 410, train_loss: 0.01271,train_acc:99.646%,test_loss: 0.86268,test_acc: 86.900%\n",
      "Epoch: 411, train_loss: 0.01303,train_acc:99.616%,test_loss: 0.83830,test_acc: 87.140%\n",
      "Epoch: 412, train_loss: 0.01436,train_acc:99.598%,test_loss: 0.88086,test_acc: 87.050%\n",
      "Epoch: 413, train_loss: 0.01205,train_acc:99.618%,test_loss: 0.86760,test_acc: 86.920%\n",
      "Epoch: 414, train_loss: 0.01562,train_acc:99.548%,test_loss: 0.87119,test_acc: 86.640%\n",
      "Epoch: 415, train_loss: 0.01516,train_acc:99.584%,test_loss: 0.86024,test_acc: 87.020%\n",
      "Epoch: 416, train_loss: 0.01379,train_acc:99.588%,test_loss: 0.85116,test_acc: 87.360%\n",
      "Epoch: 417, train_loss: 0.01200,train_acc:99.638%,test_loss: 0.86731,test_acc: 87.250%\n",
      "Epoch: 418, train_loss: 0.01652,train_acc:99.524%,test_loss: 0.89011,test_acc: 86.570%\n",
      "Epoch: 419, train_loss: 0.01710,train_acc:99.534%,test_loss: 0.80499,test_acc: 87.340%\n",
      "Epoch: 420, train_loss: 0.01059,train_acc:99.684%,test_loss: 0.83435,test_acc: 87.110%\n",
      "Epoch: 421, train_loss: 0.01263,train_acc:99.646%,test_loss: 0.85737,test_acc: 87.070%\n",
      "Epoch: 422, train_loss: 0.01350,train_acc:99.628%,test_loss: 0.88443,test_acc: 86.880%\n",
      "Epoch: 423, train_loss: 0.01286,train_acc:99.624%,test_loss: 0.84375,test_acc: 86.930%\n",
      "Epoch: 424, train_loss: 0.01378,train_acc:99.606%,test_loss: 0.84444,test_acc: 86.730%\n",
      "Epoch: 425, train_loss: 0.01436,train_acc:99.604%,test_loss: 0.89166,test_acc: 86.690%\n",
      "Epoch: 426, train_loss: 0.01110,train_acc:99.672%,test_loss: 0.87441,test_acc: 86.830%\n",
      "Epoch: 427, train_loss: 0.01494,train_acc:99.570%,test_loss: 0.85543,test_acc: 87.190%\n",
      "Epoch: 428, train_loss: 0.01298,train_acc:99.636%,test_loss: 0.88708,test_acc: 86.840%\n",
      "Epoch: 429, train_loss: 0.01407,train_acc:99.586%,test_loss: 0.85167,test_acc: 87.190%\n",
      "Epoch: 430, train_loss: 0.01317,train_acc:99.616%,test_loss: 0.84441,test_acc: 87.090%\n",
      "Epoch: 431, train_loss: 0.01396,train_acc:99.628%,test_loss: 0.85940,test_acc: 87.120%\n",
      "Epoch: 432, train_loss: 0.01370,train_acc:99.610%,test_loss: 0.85624,test_acc: 86.950%\n",
      "Epoch: 433, train_loss: 0.01363,train_acc:99.596%,test_loss: 0.87364,test_acc: 87.130%\n",
      "Epoch: 434, train_loss: 0.01479,train_acc:99.602%,test_loss: 0.86456,test_acc: 86.990%\n",
      "Epoch: 435, train_loss: 0.01433,train_acc:99.538%,test_loss: 0.91116,test_acc: 86.650%\n",
      "Epoch: 436, train_loss: 0.01490,train_acc:99.576%,test_loss: 0.86285,test_acc: 86.720%\n",
      "Epoch: 437, train_loss: 0.01160,train_acc:99.664%,test_loss: 0.85893,test_acc: 86.830%\n",
      "Epoch: 438, train_loss: 0.01316,train_acc:99.634%,test_loss: 0.90484,test_acc: 86.940%\n",
      "Epoch: 439, train_loss: 0.01269,train_acc:99.626%,test_loss: 0.86594,test_acc: 86.450%\n",
      "Epoch: 440, train_loss: 0.01246,train_acc:99.662%,test_loss: 0.86554,test_acc: 86.570%\n",
      "Epoch: 441, train_loss: 0.01388,train_acc:99.588%,test_loss: 0.86807,test_acc: 87.190%\n",
      "Epoch: 442, train_loss: 0.01104,train_acc:99.666%,test_loss: 0.87968,test_acc: 86.910%\n",
      "Epoch: 443, train_loss: 0.01372,train_acc:99.618%,test_loss: 0.86160,test_acc: 86.730%\n",
      "Epoch: 444, train_loss: 0.01313,train_acc:99.630%,test_loss: 0.84651,test_acc: 87.420%\n",
      "Epoch: 445, train_loss: 0.01379,train_acc:99.602%,test_loss: 0.86476,test_acc: 87.050%\n",
      "Epoch: 446, train_loss: 0.01418,train_acc:99.614%,test_loss: 0.87469,test_acc: 86.930%\n",
      "Epoch: 447, train_loss: 0.01276,train_acc:99.626%,test_loss: 0.88230,test_acc: 86.750%\n",
      "Epoch: 448, train_loss: 0.01366,train_acc:99.600%,test_loss: 0.88885,test_acc: 86.320%\n",
      "Epoch: 449, train_loss: 0.01395,train_acc:99.610%,test_loss: 0.87713,test_acc: 86.850%\n",
      "Epoch: 450, train_loss: 0.01285,train_acc:99.626%,test_loss: 0.86081,test_acc: 86.750%\n",
      "Epoch: 451, train_loss: 0.01298,train_acc:99.624%,test_loss: 0.86062,test_acc: 87.030%\n",
      "Epoch: 452, train_loss: 0.01261,train_acc:99.630%,test_loss: 0.87713,test_acc: 86.810%\n",
      "Epoch: 453, train_loss: 0.01286,train_acc:99.626%,test_loss: 0.84344,test_acc: 86.950%\n",
      "Epoch: 454, train_loss: 0.01292,train_acc:99.586%,test_loss: 0.82305,test_acc: 87.310%\n",
      "Epoch: 455, train_loss: 0.01242,train_acc:99.620%,test_loss: 0.82618,test_acc: 87.210%\n",
      "Epoch: 456, train_loss: 0.01373,train_acc:99.558%,test_loss: 0.86997,test_acc: 87.310%\n",
      "Epoch: 457, train_loss: 0.01225,train_acc:99.622%,test_loss: 0.85052,test_acc: 87.110%\n",
      "Epoch: 458, train_loss: 0.01218,train_acc:99.650%,test_loss: 0.88334,test_acc: 86.370%\n",
      "Epoch: 459, train_loss: 0.01363,train_acc:99.578%,test_loss: 0.85834,test_acc: 87.090%\n",
      "Epoch: 460, train_loss: 0.01327,train_acc:99.602%,test_loss: 0.84958,test_acc: 86.850%\n",
      "Epoch: 461, train_loss: 0.01231,train_acc:99.614%,test_loss: 0.86827,test_acc: 86.850%\n",
      "Epoch: 462, train_loss: 0.01189,train_acc:99.662%,test_loss: 0.88842,test_acc: 86.680%\n",
      "Epoch: 463, train_loss: 0.01370,train_acc:99.646%,test_loss: 0.88008,test_acc: 87.340%\n",
      "Epoch: 464, train_loss: 0.00944,train_acc:99.720%,test_loss: 0.87728,test_acc: 87.180%\n",
      "Epoch: 465, train_loss: 0.01165,train_acc:99.686%,test_loss: 0.82688,test_acc: 87.330%\n",
      "Epoch: 466, train_loss: 0.01305,train_acc:99.618%,test_loss: 0.86548,test_acc: 86.870%\n",
      "Epoch: 467, train_loss: 0.01266,train_acc:99.628%,test_loss: 0.84384,test_acc: 87.140%\n",
      "Epoch: 468, train_loss: 0.01021,train_acc:99.696%,test_loss: 0.85082,test_acc: 87.100%\n",
      "Epoch: 469, train_loss: 0.01106,train_acc:99.668%,test_loss: 0.87106,test_acc: 87.060%\n",
      "Epoch: 470, train_loss: 0.01293,train_acc:99.672%,test_loss: 0.86388,test_acc: 87.260%\n",
      "Epoch: 471, train_loss: 0.01025,train_acc:99.702%,test_loss: 0.83888,test_acc: 87.320%\n",
      "Epoch: 472, train_loss: 0.01268,train_acc:99.636%,test_loss: 0.86595,test_acc: 87.340%\n",
      "Epoch: 473, train_loss: 0.01441,train_acc:99.600%,test_loss: 0.87169,test_acc: 86.890%\n",
      "Epoch: 474, train_loss: 0.01122,train_acc:99.658%,test_loss: 0.87282,test_acc: 87.180%\n",
      "Epoch: 475, train_loss: 0.01100,train_acc:99.680%,test_loss: 0.86090,test_acc: 86.950%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 476, train_loss: 0.01196,train_acc:99.636%,test_loss: 0.87802,test_acc: 86.930%\n",
      "Epoch: 477, train_loss: 0.01061,train_acc:99.636%,test_loss: 0.85462,test_acc: 87.230%\n",
      "Epoch: 478, train_loss: 0.01241,train_acc:99.668%,test_loss: 0.89278,test_acc: 87.040%\n",
      "Epoch: 479, train_loss: 0.01291,train_acc:99.646%,test_loss: 0.85172,test_acc: 87.300%\n",
      "Epoch: 480, train_loss: 0.01422,train_acc:99.588%,test_loss: 0.85750,test_acc: 87.120%\n",
      "Epoch: 481, train_loss: 0.01286,train_acc:99.644%,test_loss: 0.86737,test_acc: 87.190%\n",
      "Epoch: 482, train_loss: 0.01051,train_acc:99.716%,test_loss: 0.85817,test_acc: 86.790%\n",
      "Epoch: 483, train_loss: 0.01073,train_acc:99.704%,test_loss: 0.85364,test_acc: 87.290%\n",
      "Epoch: 484, train_loss: 0.01094,train_acc:99.684%,test_loss: 0.87673,test_acc: 87.230%\n",
      "Epoch: 485, train_loss: 0.01131,train_acc:99.686%,test_loss: 0.85618,test_acc: 87.190%\n",
      "Epoch: 486, train_loss: 0.01066,train_acc:99.718%,test_loss: 0.86428,test_acc: 87.060%\n",
      "Epoch: 487, train_loss: 0.01080,train_acc:99.656%,test_loss: 0.87915,test_acc: 86.590%\n",
      "Epoch: 488, train_loss: 0.01224,train_acc:99.650%,test_loss: 0.84542,test_acc: 87.230%\n",
      "Epoch: 489, train_loss: 0.01039,train_acc:99.692%,test_loss: 0.87062,test_acc: 86.900%\n",
      "Epoch: 490, train_loss: 0.01009,train_acc:99.684%,test_loss: 0.88002,test_acc: 86.910%\n",
      "Epoch: 491, train_loss: 0.01172,train_acc:99.682%,test_loss: 0.90888,test_acc: 87.060%\n",
      "Epoch: 492, train_loss: 0.01305,train_acc:99.622%,test_loss: 0.88934,test_acc: 86.890%\n",
      "Epoch: 493, train_loss: 0.01216,train_acc:99.644%,test_loss: 0.87581,test_acc: 87.090%\n",
      "Epoch: 494, train_loss: 0.01125,train_acc:99.714%,test_loss: 0.87441,test_acc: 87.160%\n",
      "Epoch: 495, train_loss: 0.01023,train_acc:99.722%,test_loss: 0.87753,test_acc: 86.880%\n",
      "Epoch: 496, train_loss: 0.01122,train_acc:99.658%,test_loss: 0.88514,test_acc: 86.720%\n",
      "Epoch: 497, train_loss: 0.00885,train_acc:99.756%,test_loss: 0.88789,test_acc: 87.020%\n",
      "Epoch: 498, train_loss: 0.00912,train_acc:99.742%,test_loss: 0.88855,test_acc: 86.800%\n",
      "Epoch: 499, train_loss: 0.01207,train_acc:99.646%,test_loss: 0.88989,test_acc: 86.920%\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "MI_sample = np.zeros([1,2,16])\n",
    "for epoch in range(500):\n",
    "    \n",
    "    train_avg_loss.reset_states()\n",
    "    test_avg_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "    \n",
    "    for x_train_batch,y_train_batch in train_loader:\n",
    "        train_step(x_train_batch,y_train_batch)\n",
    "    train_loss.append(train_avg_loss.result())\n",
    "    train_acc.append(train_accuracy.result())\n",
    "\n",
    "    \n",
    "    output = model(x_train_batch,training=False)\n",
    "    output.append(x_train_batch)\n",
    "    y_tr_batch = tf.cast(y_train_batch, tf.float32)\n",
    "    output.append(y_tr_batch)\n",
    "    \n",
    "    MI_x=np.zeros(16)\n",
    "    MI_y=np.zeros(16)\n",
    "    for i in range(16):\n",
    "        MI_x[i] = model.calculate_MI(output[-2],output[i])\n",
    "        MI_y[i] = model.calculate_MI(output[i],output[-1])\n",
    "    MI_xy = np.vstack((MI_x,MI_y))\n",
    "    MI_xy = MI_xy.reshape([1,2,16])\n",
    "\n",
    "    \n",
    "    for x_test_batch,y_test_batch in test_loader:\n",
    "        test_step(x_test_batch,y_test_batch)\n",
    "    test_loss.append(test_avg_loss.result())\n",
    "    test_acc.append(test_accuracy.result())\n",
    "    \n",
    "    print(\"Epoch: {}, train_loss: {:.5f},train_acc:{:.3%},test_loss: {:.5f},test_acc: {:.3%}\"\n",
    "          .format(epoch,train_avg_loss.result(),\n",
    "                  train_accuracy.result(),\n",
    "                  test_avg_loss.result(),\n",
    "                 test_accuracy.result())) \n",
    "    \n",
    "    MI_sample = np.vstack((MI_sample,MI_xy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "MI_sample1 = MI_sample[1:]\n",
    "MI_sample1.shape\n",
    "np.save('MI.npy',MI_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f497da62d90>]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "MI_1 = np.flip(MI_sample[400,0,:])\n",
    "plt.plot(MI_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f497d792dd0>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch = np.arange(0,500,1)\n",
    "MI_layer1 = MI_sample1[:,:,12]\n",
    "MI_layer1.shape\n",
    "plt.scatter(MI_layer1[0:100,0],MI_layer1[0:100,1],c=np.arange(0,100,1))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(x_train_batch,training=False)\n",
    "output.append(x_train_batch)\n",
    "output.append(y_train_batch)\n",
    "MI_x=np.zeros(16)\n",
    "MI_y=np.zeros(16)\n",
    "for i in range(16):\n",
    "    MI_x[i] = model.calculate_MI(output[-2],output[i])\n",
    "    #MI_y[i] = model.calculate_MI(output[i],output[-1])\n",
    "MI_xy = np.vstack((MI_x,MI_y))\n",
    "MI_xy = MI_xy.reshape([1,2,16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.array(train_loss),label='train_dis_loss')\n",
    "plt.plot(np.array(test_loss),label='test_gen_loss')\n",
    "#plt.plot(np.array(test_dis))\n",
    "#plt.plot(np.array(test_gen))\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel(\"epoach\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.ylim([0,2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('vgg16_180.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('vgg16_180.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
